{"docstore/metadata": {"1dafc231-ac33-42a2-9ba6-51f57e50c745": {"doc_hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831"}, "ffa913d6-c325-43cc-9dcb-88ff057cd299": {"doc_hash": "a39d72aaaa199b4ba2df4daef920af547ce779a51d260e6920e060e85f65d7cc", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "e817ba43-2e88-4f2a-9312-c8e8b2bec861": {"doc_hash": "64719a1d6b20e8dc5e81dded9e0d25eb86747ce154cf3ef8bb0ed1c2f3a9210c", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3": {"doc_hash": "10576b79e061b5513185a4afd8e8ea924bf7f4a527a52d5a29bd661262157821", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "0b095bdf-d36b-4cb1-9daf-b825fccc4454": {"doc_hash": "6b6564b73748f5d4d344fc0e8f967e716a220464fd61d3065810b1d651bea933", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "3f5f9832-7688-4224-a518-9f4fc121f9f0": {"doc_hash": "a393f1884115a63e60f1ab61eb888553d3f43467bd3c88d90b53da09c983c83e", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "2302ec12-42e0-401f-a583-e8eda45ffa5c": {"doc_hash": "a242579327bd95731bbf68c0db303d28bf2db86d921376a43440e53dcdb25490", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a": {"doc_hash": "c63b9faa481e4875d78177027d9f9c018ff06490b0d35b462604b205d2c13ced", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "2c4ef1d9-e443-4aa2-ae6f-86accede988f": {"doc_hash": "33016b007c308d18df6df067bab390332de1c8044f47dfa439c65745b4feb6aa", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "4af45910-e0cc-4b75-9e08-244fe6521e48": {"doc_hash": "3589ce23c6907dce6006992eecc303c44ad430bed41319f32166723b11345748", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "18fcb37a-0626-46dc-ba3a-14926ba7fecc": {"doc_hash": "35962d734e574d1a6befe75df9f67412758572671c8a6948dae3aad677fa3ca1", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "8407cd9a-84c0-47bb-8e34-3605577eb0cb": {"doc_hash": "00f3ee3290ab3aa9a08a292394bac33c48b5c502639336212b3d29edc7274d64", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "fd851d4a-b424-4e30-a021-f3305816aa79": {"doc_hash": "b546280222bea399e0ee826c7db9cd37c1770921807179749efb1bf2b048e83a", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "195e5394-e1ed-4853-bfc1-ed656d7cf660": {"doc_hash": "c89656ece9d2350bb8afd1ca4183a8fed168ef49655cc04c6a77df9c72975313", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6": {"doc_hash": "1101e92d712c0c4f0e3dd6740152fab3711cce15ce22338fcb8df494e5928812", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "b5538188-352c-42a8-9b6e-8ab697391766": {"doc_hash": "9ae8dcced0a1eae4275047b85e2b44ce67f9f79e5ab0f6eac879933ee6bc37db", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "66f4cf08-6189-4075-9bc4-12232900e7ba": {"doc_hash": "b0a8c4588bdc50d2c7efb13d2234fc4d17d556d8ba8299c73c137650bac9c558", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "7bf5d248-bf26-4d2b-b4a4-867a5a070e89": {"doc_hash": "1fee176a5f1498e79d9385349aa235f08a9be8500588443c1c3c7e38d9196644", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a": {"doc_hash": "3649dff62c72d8f41904fcd9e337e60588de55475e50c301bbe0de3f5328f230", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9": {"doc_hash": "47075a566e78fe51a5721dafb27e515bf945a5d3ab862ce4ed3de0b1c0d764dd", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "5977c7fd-8154-47ac-88c1-a7ec95eac8a3": {"doc_hash": "0e462f518f95ade986b125aed7ffb8dae9bb6fe9cafc2deaaa28a1642678a805", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "09d5e4de-49e7-476e-8e10-753bec7a5217": {"doc_hash": "356cac4388c805f26cf74a6af27b37d05a53b685f05be03d96ad8a181ea81830", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}, "ec258b35-78d6-4569-ac78-ee008449df60": {"doc_hash": "2f7a0a3d381e24f9ae185bd9fa888613e8e7a2a4f104c5837030181b988c0425", "ref_doc_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745"}}, "docstore/data": {"ffa913d6-c325-43cc-9dcb-88ff057cd299": {"__data__": {"id_": "ffa913d6-c325-43cc-9dcb-88ff057cd299", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e817ba43-2e88-4f2a-9312-c8e8b2bec861", "node_type": "1", "metadata": {}, "hash": "680d42a482815bc66548ebdcb141d93a6eab3bf6e29cbb370ab80c66a55cb43f", "class_name": "RelatedNodeInfo"}}, "text": "source: https://pytorch.org/tutorials/beginner/basics/intro.html \r\ncontent: \r\n\r\nNote\r\nClick here\r\nto download the full example code\r\nLearn the Basics ||\r\nQuickstart ||\r\nTensors ||\r\nDatasets & DataLoaders ||\r\nTransforms ||\r\nBuild Model ||\r\nAutograd ||\r\nOptimization ||\r\nSave & Load Model\r\nLearn the Basics\u00b6\r\nAuthors:\r\nSuraj Subramanian,\r\nSeth Juarez,\r\nCassie Breviu,\r\nDmitry Soshnikov,\r\nAri Bornstein\r\nMost machine learning workflows involve working with data, creating models, optimizing model\r\nparameters, and saving the trained models. This tutorial introduces you to a complete ML workflow\r\nimplemented in PyTorch, with links to learn more about each of these concepts.\r\nWe\u2019ll use the FashionMNIST dataset to train a neural network that predicts if an input image belongs\r\nto one of the following classes: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker,\r\nBag, or Ankle boot.\r\nThis tutorial assumes a basic familiarity with Python and Deep Learning concepts.\r\nRunning the Tutorial Code\u00b6\r\nYou can run this tutorial in a couple of ways:\r\nIn the cloud: This is the easiest way to get started! Each section has a \u201cRun in Microsoft Learn\u201d and \u201cRun in Google Colab\u201d link at the top, which opens an integrated notebook in Microsoft Learn or Google Colab, respectively, with the code in a fully-hosted environment.\r\nLocally: This option requires you to setup PyTorch and TorchVision first on your local machine (installation instructions). Download the notebook or copy the code into your favorite IDE.\r\nHow to Use this Guide\u00b6\r\nIf you\u2019re familiar with other deep learning frameworks, check out the 0. Quickstart first\r\nto quickly familiarize yourself with PyTorch\u2019s API.\r\nIf you\u2019re new to deep learning frameworks, head right into the first section of our step-by-step guide: 1. Tensors.\r\nTotal running time of the script: ( 0 minutes  0.000 seconds)\r\nDownload Python source code: intro.py\r\nDownload Jupyter notebook: intro.ipynb\r\nGallery generated by Sphinx-Gallery \r\n\r\nsource: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html \r\ncontent: \r\n\r\nDeep Learning with PyTorch: A 60 Minute Blitz\u00b6\r\nAuthor: Soumith Chintala\r\nWhat is PyTorch?\u00b6\r\nPyTorch is a Python-based scientific computing package serving two broad purposes:\r\nA replacement for NumPy to use the power of GPUs and other accelerators.\r\nAn automatic differentiation library that is useful to implement neural networks.\r\nGoal of this tutorial:\u00b6\r\nUnderstand PyTorch\u2019s Tensor library and neural networks at a high level.\r\nTrain a small neural network to classify images\r\nTo run the tutorials below, make sure you have the torch, torchvision,\r\nand matplotlib packages installed.\r\nIn this tutorial, you will learn the basics of PyTorch tensors.\r\n Code\r\nLearn about autograd.\r\n Code\r\nThis tutorial demonstrates how you can train neural networks in PyTorch.\r\n Code\r\nLearn how to train an image classifier in PyTorch by using the\r\nCIFAR10 dataset.\r\n Code \r\n\r\nsource: https://pytorch.org/tutorials/beginner/nn_tutorial.html \r\ncontent: \r\n\r\nNote\r\nClick here\r\nto download the full example code\r\nWhat is torch.nn really?\u00b6\r\nAuthors: Jeremy Howard, fast.ai. Thanks to Rachel Thomas and Francisco Ingham.\r\nWe recommend running this tutorial as a notebook, not a script. To download the notebook (.ipynb) file,\r\nclick the link at the top of the page.\r\nPyTorch provides the elegantly designed modules and classes torch.nn ,\r\ntorch.optim ,\r\nDataset ,\r\nand DataLoader\r\nto help you create and train neural networks.\r\nIn order to fully utilize their power and customize\r\nthem for your problem, you need to really understand exactly what they\u2019re\r\ndoing. To develop this understanding, we will first train basic neural net\r\non the MNIST data set without using any features from these models; we will\r\ninitially only use the most basic PyTorch tensor functionality. Then, we will\r\nincrementally add one feature from torch.nn, torch.optim, Dataset, or\r\nDataLoader at a time, showing exactly what each piece does, and how it\r\nworks to make the code either more concise, or more flexible.\r\nThis tutorial assumes you already have PyTorch installed, and are familiar\r\nwith the basics of tensor operations. (If you\u2019re familiar with Numpy array\r\noperations, you\u2019ll find the PyTorch tensor operations used here nearly identical).\r\nMNIST data setup\u00b6\r\nWe will use the classic MNIST dataset,\r\nwhich consists of black-and-white images of hand-drawn digits (between 0 and 9).", "mimetype": "text/plain", "start_char_idx": 5, "end_char_idx": 4435, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e817ba43-2e88-4f2a-9312-c8e8b2bec861": {"__data__": {"id_": "e817ba43-2e88-4f2a-9312-c8e8b2bec861", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffa913d6-c325-43cc-9dcb-88ff057cd299", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "a39d72aaaa199b4ba2df4daef920af547ce779a51d260e6920e060e85f65d7cc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3", "node_type": "1", "metadata": {}, "hash": "5faf736228b8ddf905d0bd77ab53f43bf74bec102360ddad83c6efb07ca948bc", "class_name": "RelatedNodeInfo"}}, "text": "To develop this understanding, we will first train basic neural net\r\non the MNIST data set without using any features from these models; we will\r\ninitially only use the most basic PyTorch tensor functionality. Then, we will\r\nincrementally add one feature from torch.nn, torch.optim, Dataset, or\r\nDataLoader at a time, showing exactly what each piece does, and how it\r\nworks to make the code either more concise, or more flexible.\r\nThis tutorial assumes you already have PyTorch installed, and are familiar\r\nwith the basics of tensor operations. (If you\u2019re familiar with Numpy array\r\noperations, you\u2019ll find the PyTorch tensor operations used here nearly identical).\r\nMNIST data setup\u00b6\r\nWe will use the classic MNIST dataset,\r\nwhich consists of black-and-white images of hand-drawn digits (between 0 and 9).\r\nWe will use pathlib\r\nfor dealing with paths (part of the Python 3 standard library), and will\r\ndownload the dataset using\r\nrequests. We will only\r\nimport modules when we use them, so you can see exactly what\u2019s being\r\nused at each point.\r\nfrom pathlib import Path\r\nimport requests\r\n\r\nDATA_PATH = Path(\"data\")\r\nPATH = DATA_PATH / \"mnist\"\r\n\r\nPATH.mkdir(parents=True, exist_ok=True)\r\n\r\nURL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\r\nFILENAME = \"mnist.pkl.gz\"\r\n\r\nif not (PATH / FILENAME).exists():\r\n        content = requests.get(URL + FILENAME).content\r\n        (PATH / FILENAME).open(\"wb\").write(content)\r\n\r\nThis dataset is in numpy array format, and has been stored using pickle,\r\na python-specific format for serializing data.\r\nimport pickle\r\nimport gzip\r\n\r\nwith gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\r\n        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\r\n\r\nEach image is 28 x 28, and is being stored as a flattened row of length\r\n784 (=28x28). Let\u2019s take a look at one; we need to reshape it to 2d\r\nfirst.\r\nfrom matplotlib import pyplot\r\nimport numpy as np\r\n\r\npyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\r\n# ``pyplot.show()`` only if not on Colab\r\ntry:\r\n    import google.colab\r\nexcept ImportError:\r\n    pyplot.show()\r\nprint(x_train.shape)\r\n\r\n(50000, 784)\r\n\r\nPyTorch uses torch.tensor, rather than numpy arrays, so we need to\r\nconvert our data.\r\nimport torch\r\n\r\nx_train, y_train, x_valid, y_valid = map(\r\n    torch.tensor, (x_train, y_train, x_valid, y_valid)\r\n)\r\nn, c = x_train.shape\r\nprint(x_train, y_train)\r\nprint(x_train.shape)\r\nprint(y_train.min(), y_train.max())\r\n\r\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\r\n        [0., 0., 0.,  ..., 0., 0., 0.],\r\n        [0., 0., 0.,  ..., 0., 0., 0.],\r\n        ...,\r\n        [0., 0., 0.,  ..., 0., 0., 0.],\r\n        [0., 0., 0.,  ..., 0., 0., 0.],\r\n        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\r\ntorch.Size([50000, 784])\r\ntensor(0) tensor(9)\r\n\r\nNeural net from scratch (without torch.nn)\u00b6\r\nLet\u2019s first create a model using nothing but PyTorch tensor operations. We\u2019re assuming\r\nyou\u2019re already familiar with the basics of neural networks. (If you\u2019re not, you can\r\nlearn them at course.fast.ai).\r\nPyTorch provides methods to create random or zero-filled tensors, which we will\r\nuse to create our weights and bias for a simple linear model. These are just regular\r\ntensors, with one very special addition: we tell PyTorch that they require a\r\ngradient. This causes PyTorch to record all of the operations done on the tensor,\r\nso that it can calculate the gradient during back-propagation automatically!\r\nFor the weights, we set requires_grad after the initialization, since we\r\ndon\u2019t want that step included in the gradient. (Note that a trailing _ in\r\nPyTorch signifies that the operation is performed in-place.)\r\nNote\r\nWe are initializing the weights here with\r\nXavier initialisation\r\n(by multiplying with 1/sqrt(n)).", "mimetype": "text/plain", "start_char_idx": 3629, "end_char_idx": 7402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3": {"__data__": {"id_": "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e817ba43-2e88-4f2a-9312-c8e8b2bec861", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "64719a1d6b20e8dc5e81dded9e0d25eb86747ce154cf3ef8bb0ed1c2f3a9210c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b095bdf-d36b-4cb1-9daf-b825fccc4454", "node_type": "1", "metadata": {}, "hash": "f5ab95e888ced775b78bcde64f05c345da107eca69abdd5fd403f7a91fd9e782", "class_name": "RelatedNodeInfo"}}, "text": "We\u2019re assuming\r\nyou\u2019re already familiar with the basics of neural networks. (If you\u2019re not, you can\r\nlearn them at course.fast.ai).\r\nPyTorch provides methods to create random or zero-filled tensors, which we will\r\nuse to create our weights and bias for a simple linear model. These are just regular\r\ntensors, with one very special addition: we tell PyTorch that they require a\r\ngradient. This causes PyTorch to record all of the operations done on the tensor,\r\nso that it can calculate the gradient during back-propagation automatically!\r\nFor the weights, we set requires_grad after the initialization, since we\r\ndon\u2019t want that step included in the gradient. (Note that a trailing _ in\r\nPyTorch signifies that the operation is performed in-place.)\r\nNote\r\nWe are initializing the weights here with\r\nXavier initialisation\r\n(by multiplying with 1/sqrt(n)).\r\nimport math\r\n\r\nweights = torch.randn(784, 10) / math.sqrt(784)\r\nweights.requires_grad_()\r\nbias = torch.zeros(10, requires_grad=True)\r\n\r\nThanks to PyTorch\u2019s ability to calculate gradients automatically, we can\r\nuse any standard Python function (or callable object) as a model! So\r\nlet\u2019s just write a plain matrix multiplication and broadcasted addition\r\nto create a simple linear model. We also need an activation function, so\r\nwe\u2019ll write log_softmax and use it. Remember: although PyTorch\r\nprovides lots of prewritten loss functions, activation functions, and\r\nso forth, you can easily write your own using plain python. PyTorch will\r\neven create fast GPU or vectorized CPU code for your function\r\nautomatically.\r\ndef log_softmax(x):\r\n    return x - x.exp().sum(-1).log().unsqueeze(-1)\r\n\r\ndef model(xb):\r\n    return log_softmax(xb @ weights + bias)\r\n\r\nIn the above, the @ stands for the matrix multiplication operation. We will call\r\nour function on one batch of data (in this case, 64 images).  This is\r\none forward pass.  Note that our predictions won\u2019t be any better than\r\nrandom at this stage, since we start with random weights.\r\nbs = 64  # batch size\r\n\r\nxb = x_train[0:bs]  # a mini-batch from x\r\npreds = model(xb)  # predictions\r\npreds[0], preds.shape\r\nprint(preds[0], preds.shape)\r\n\r\ntensor([-2.5452, -2.0790, -2.1832, -2.6221, -2.3670, -2.3854, -2.9432, -2.4391,\r\n        -1.8657, -2.0355], grad_fn=<SelectBackward0>) torch.Size([64, 10])\r\n\r\nAs you see, the preds tensor contains not only the tensor values, but also a\r\ngradient function. We\u2019ll use this later to do backprop.\r\nLet\u2019s implement negative log-likelihood to use as the loss function\r\n(again, we can just use standard Python):\r\ndef nll(input, target):\r\n    return -input[range(target.shape[0]), target].mean()\r\n\r\nloss_func = nll\r\n\r\nLet\u2019s check our loss with our random model, so we can see if we improve\r\nafter a backprop pass later.\r\nyb = y_train[0:bs]\r\nprint(loss_func(preds, yb))\r\n\r\ntensor(2.4020, grad_fn=<NegBackward0>)\r\n\r\nLet\u2019s also implement a function to calculate the accuracy of our model.\r\nFor each prediction, if the index with the largest value matches the\r\ntarget value, then the prediction was correct.\r\ndef accuracy(out, yb):\r\n    preds = torch.argmax(out, dim=1)\r\n    return (preds == yb).float().mean()\r\n\r\nLet\u2019s check the accuracy of our random model, so we can see if our\r\naccuracy improves as our loss improves.\r\nprint(accuracy(preds, yb))\r\n\r\ntensor(0.0938)\r\n\r\nWe can now run a training loop.  For each iteration, we will:\r\nselect a mini-batch of data (of size bs)\r\nuse the model to make predictions\r\ncalculate the loss\r\nloss.backward() updates the gradients of the model, in this case, weights\r\nand bias.\r\nWe now use these gradients to update the weights and bias.  We do this\r\nwithin the torch.no_grad() context manager, because we do not want these\r\nactions to be recorded for our next calculation of the gradient.  You can read\r\nmore about how PyTorch\u2019s Autograd records operations\r\nhere.\r\nWe then set the\r\ngradients to zero, so that we are ready for the next loop.\r\nOtherwise, our gradients would record a running tally of all the operations\r\nthat had happened (i.e.", "mimetype": "text/plain", "start_char_idx": 6548, "end_char_idx": 10566, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b095bdf-d36b-4cb1-9daf-b825fccc4454": {"__data__": {"id_": "0b095bdf-d36b-4cb1-9daf-b825fccc4454", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "10576b79e061b5513185a4afd8e8ea924bf7f4a527a52d5a29bd661262157821", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f5f9832-7688-4224-a518-9f4fc121f9f0", "node_type": "1", "metadata": {}, "hash": "48403f1592b8d71f33ec25e24eb71245b8e1d0495aa930e1f5da18d06620244f", "class_name": "RelatedNodeInfo"}}, "text": "print(accuracy(preds, yb))\r\n\r\ntensor(0.0938)\r\n\r\nWe can now run a training loop.  For each iteration, we will:\r\nselect a mini-batch of data (of size bs)\r\nuse the model to make predictions\r\ncalculate the loss\r\nloss.backward() updates the gradients of the model, in this case, weights\r\nand bias.\r\nWe now use these gradients to update the weights and bias.  We do this\r\nwithin the torch.no_grad() context manager, because we do not want these\r\nactions to be recorded for our next calculation of the gradient.  You can read\r\nmore about how PyTorch\u2019s Autograd records operations\r\nhere.\r\nWe then set the\r\ngradients to zero, so that we are ready for the next loop.\r\nOtherwise, our gradients would record a running tally of all the operations\r\nthat had happened (i.e. loss.backward() adds the gradients to whatever is\r\nalready stored, rather than replacing them).\r\nTip\r\nYou can use the standard python debugger to step through PyTorch\r\ncode, allowing you to check the various variable values at each step.\r\nUncomment set_trace() below to try it out.\r\nfrom IPython.core.debugger import set_trace\r\n\r\nlr = 0.5  # learning rate\r\nepochs = 2  # how many epochs to train for\r\n\r\nfor epoch in range(epochs):\r\n    for i in range((n - 1) // bs + 1):\r\n        #         set_trace()\r\n        start_i = i * bs\r\n        end_i = start_i + bs\r\n        xb = x_train[start_i:end_i]\r\n        yb = y_train[start_i:end_i]\r\n        pred = model(xb)\r\n        loss = loss_func(pred, yb)\r\n\r\n        loss.backward()\r\n        with torch.no_grad():\r\n            weights -= weights.grad * lr\r\n            bias -= bias.grad * lr\r\n            weights.grad.zero_()\r\n            bias.grad.zero_()\r\n\r\nThat\u2019s it: we\u2019ve created and trained a minimal neural network (in this case, a\r\nlogistic regression, since we have no hidden layers) entirely from scratch!\r\nLet\u2019s check the loss and accuracy and compare those to what we got\r\nearlier. We expect that the loss will have decreased and accuracy to\r\nhave increased, and they have.\r\nprint(loss_func(model(xb), yb), accuracy(model(xb), yb))\r\n\r\ntensor(0.0813, grad_fn=<NegBackward0>) tensor(1.)\r\n\r\nUsing torch.nn.functional\u00b6\r\nWe will now refactor our code, so that it does the same thing as before, only\r\nwe\u2019ll start taking advantage of PyTorch\u2019s nn classes to make it more concise\r\nand flexible. At each step from here, we should be making our code one or more\r\nof: shorter, more understandable, and/or more flexible.\r\nThe first and easiest step is to make our code shorter by replacing our\r\nhand-written activation and loss functions with those from torch.nn.functional\r\n(which is generally imported into the namespace F by convention). This module\r\ncontains all the functions in the torch.nn library (whereas other parts of the\r\nlibrary contain classes). As well as a wide range of loss and activation\r\nfunctions, you\u2019ll also find here some convenient functions for creating neural\r\nnets, such as pooling functions. (There are also functions for doing convolutions,\r\nlinear layers, etc, but as we\u2019ll see, these are usually better handled using\r\nother parts of the library.)\r\nIf you\u2019re using negative log likelihood loss and log softmax activation,\r\nthen Pytorch provides a single function F.cross_entropy that combines\r\nthe two. So we can even remove the activation function from our model.\r\nimport torch.nn.functional as F\r\n\r\nloss_func = F.cross_entropy\r\n\r\ndef model(xb):\r\n    return xb @ weights + bias\r\n\r\nNote that we no longer call log_softmax in the model function. Let\u2019s\r\nconfirm that our loss and accuracy are the same as before:\r\nprint(loss_func(model(xb), yb), accuracy(model(xb), yb))\r\n\r\ntensor(0.0813, grad_fn=<NllLossBackward0>) tensor(1.)\r\n\r\nRefactor using nn.Module\u00b6\r\nNext up, we\u2019ll use nn.Module and nn.Parameter, for a clearer and more\r\nconcise training loop. We subclass nn.Module (which itself is a class and\r\nable to keep track of state).  In this case, we want to create a class that\r\nholds our weights, bias, and method for the forward step.  nn.Module has a\r\nnumber of attributes and methods (such as .parameters() and .zero_grad())\r\nwhich we will be using.\r\nNote\r\nnn.Module (uppercase M) is a PyTorch specific concept, and is a\r\nclass we\u2019ll be using a lot.", "mimetype": "text/plain", "start_char_idx": 9808, "end_char_idx": 13989, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3f5f9832-7688-4224-a518-9f4fc121f9f0": {"__data__": {"id_": "3f5f9832-7688-4224-a518-9f4fc121f9f0", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b095bdf-d36b-4cb1-9daf-b825fccc4454", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "6b6564b73748f5d4d344fc0e8f967e716a220464fd61d3065810b1d651bea933", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2302ec12-42e0-401f-a583-e8eda45ffa5c", "node_type": "1", "metadata": {}, "hash": "fdf5a7805d9fabab8e2dd9eaa35c7158612672bc2199fa01947256df028b82ac", "class_name": "RelatedNodeInfo"}}, "text": "Let\u2019s\r\nconfirm that our loss and accuracy are the same as before:\r\nprint(loss_func(model(xb), yb), accuracy(model(xb), yb))\r\n\r\ntensor(0.0813, grad_fn=<NllLossBackward0>) tensor(1.)\r\n\r\nRefactor using nn.Module\u00b6\r\nNext up, we\u2019ll use nn.Module and nn.Parameter, for a clearer and more\r\nconcise training loop. We subclass nn.Module (which itself is a class and\r\nable to keep track of state).  In this case, we want to create a class that\r\nholds our weights, bias, and method for the forward step.  nn.Module has a\r\nnumber of attributes and methods (such as .parameters() and .zero_grad())\r\nwhich we will be using.\r\nNote\r\nnn.Module (uppercase M) is a PyTorch specific concept, and is a\r\nclass we\u2019ll be using a lot. nn.Module is not to be confused with the Python\r\nconcept of a (lowercase m) module,\r\nwhich is a file of Python code that can be imported.\r\nfrom torch import nn\r\n\r\nclass Mnist_Logistic(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\r\n        self.bias = nn.Parameter(torch.zeros(10))\r\n\r\n    def forward(self, xb):\r\n        return xb @ self.weights + self.bias\r\n\r\nSince we\u2019re now using an object instead of just using a function, we\r\nfirst have to instantiate our model:\r\nmodel = Mnist_Logistic()\r\n\r\nNow we can calculate the loss in the same way as before. Note that\r\nnn.Module objects are used as if they are functions (i.e they are\r\ncallable), but behind the scenes Pytorch will call our forward\r\nmethod automatically.\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(2.3096, grad_fn=<NllLossBackward0>)\r\n\r\nPreviously for our training loop we had to update the values for each parameter\r\nby name, and manually zero out the grads for each parameter separately, like this:\r\nwith torch.no_grad():\r\n    weights -= weights.grad * lr\r\n    bias -= bias.grad * lr\r\n    weights.grad.zero_()\r\n    bias.grad.zero_()\r\n\r\nNow we can take advantage of model.parameters() and model.zero_grad() (which\r\nare both defined by PyTorch for nn.Module) to make those steps more concise\r\nand less prone to the error of forgetting some of our parameters, particularly\r\nif we had a more complicated model:\r\nwith torch.no_grad():\r\n    for p in model.parameters(): p -= p.grad * lr\r\n    model.zero_grad()\r\n\r\nWe\u2019ll wrap our little training loop in a fit function so we can run it\r\nagain later.\r\ndef fit():\r\n    for epoch in range(epochs):\r\n        for i in range((n - 1) // bs + 1):\r\n            start_i = i * bs\r\n            end_i = start_i + bs\r\n            xb = x_train[start_i:end_i]\r\n            yb = y_train[start_i:end_i]\r\n            pred = model(xb)\r\n            loss = loss_func(pred, yb)\r\n\r\n            loss.backward()\r\n            with torch.no_grad():\r\n                for p in model.parameters():\r\n                    p -= p.grad * lr\r\n                model.zero_grad()\r\n\r\nfit()\r\n\r\nLet\u2019s double-check that our loss has gone down:\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(0.0821, grad_fn=<NllLossBackward0>)\r\n\r\nRefactor using nn.Linear\u00b6\r\nWe continue to refactor our code.  Instead of manually defining and\r\ninitializing self.weights and self.bias, and calculating xb\u00a0 @\r\nself.weights + self.bias, we will instead use the Pytorch class\r\nnn.Linear for a\r\nlinear layer, which does all that for us. Pytorch has many types of\r\npredefined layers that can greatly simplify our code, and often makes it\r\nfaster too.\r\nclass Mnist_Logistic(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.lin = nn.Linear(784, 10)\r\n\r\n    def forward(self, xb):\r\n        return self.lin(xb)\r\n\r\nWe instantiate our model and calculate the loss in the same way as before:\r\nmodel = Mnist_Logistic()\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(2.3313, grad_fn=<NllLossBackward0>)\r\n\r\nWe are still able to use our same fit method as before.\r\nfit()\r\n\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(0.0819, grad_fn=<NllLossBackward0>)\r\n\r\nRefactor using torch.optim\u00b6\r\nPytorch also has a package with various optimization algorithms, torch.optim.\r\nWe can use the step method from our optimizer to take a forward step, instead\r\nof manually updating each parameter.", "mimetype": "text/plain", "start_char_idx": 13281, "end_char_idx": 17411, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2302ec12-42e0-401f-a583-e8eda45ffa5c": {"__data__": {"id_": "2302ec12-42e0-401f-a583-e8eda45ffa5c", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f5f9832-7688-4224-a518-9f4fc121f9f0", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "a393f1884115a63e60f1ab61eb888553d3f43467bd3c88d90b53da09c983c83e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a", "node_type": "1", "metadata": {}, "hash": "01c4e267e12d0d330fd47d0874c2070552d9b3655a99f880b59bab6b327de8eb", "class_name": "RelatedNodeInfo"}}, "text": "class Mnist_Logistic(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.lin = nn.Linear(784, 10)\r\n\r\n    def forward(self, xb):\r\n        return self.lin(xb)\r\n\r\nWe instantiate our model and calculate the loss in the same way as before:\r\nmodel = Mnist_Logistic()\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(2.3313, grad_fn=<NllLossBackward0>)\r\n\r\nWe are still able to use our same fit method as before.\r\nfit()\r\n\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(0.0819, grad_fn=<NllLossBackward0>)\r\n\r\nRefactor using torch.optim\u00b6\r\nPytorch also has a package with various optimization algorithms, torch.optim.\r\nWe can use the step method from our optimizer to take a forward step, instead\r\nof manually updating each parameter.\r\nThis will let us replace our previous manually coded optimization step:\r\nwith torch.no_grad():\r\n    for p in model.parameters(): p -= p.grad * lr\r\n    model.zero_grad()\r\n\r\nand instead use just:\r\nopt.step()\r\nopt.zero_grad()\r\n\r\n(optim.zero_grad() resets the gradient to 0 and we need to call it before\r\ncomputing the gradient for the next minibatch.)\r\nfrom torch import optim\r\n\r\nWe\u2019ll define a little function to create our model and optimizer so we\r\ncan reuse it in the future.\r\ndef get_model():\r\n    model = Mnist_Logistic()\r\n    return model, optim.SGD(model.parameters(), lr=lr)\r\n\r\nmodel, opt = get_model()\r\nprint(loss_func(model(xb), yb))\r\n\r\nfor epoch in range(epochs):\r\n    for i in range((n - 1) // bs + 1):\r\n        start_i = i * bs\r\n        end_i = start_i + bs\r\n        xb = x_train[start_i:end_i]\r\n        yb = y_train[start_i:end_i]\r\n        pred = model(xb)\r\n        loss = loss_func(pred, yb)\r\n\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(2.2659, grad_fn=<NllLossBackward0>)\r\ntensor(0.0810, grad_fn=<NllLossBackward0>)\r\n\r\nRefactor using Dataset\u00b6\r\nPyTorch has an abstract Dataset class.  A Dataset can be anything that has\r\na __len__ function (called by Python\u2019s standard len function) and\r\na __getitem__ function as a way of indexing into it.\r\nThis tutorial\r\nwalks through a nice example of creating a custom FacialLandmarkDataset class\r\nas a subclass of Dataset.\r\nPyTorch\u2019s TensorDataset\r\nis a Dataset wrapping tensors. By defining a length and way of indexing,\r\nthis also gives us a way to iterate, index, and slice along the first\r\ndimension of a tensor. This will make it easier to access both the\r\nindependent and dependent variables in the same line as we train.\r\nfrom torch.utils.data import TensorDataset\r\n\r\nBoth x_train and y_train can be combined in a single TensorDataset,\r\nwhich will be easier to iterate over and slice.\r\ntrain_ds = TensorDataset(x_train, y_train)\r\n\r\nPreviously, we had to iterate through minibatches of x and y values separately:\r\nxb = x_train[start_i:end_i]\r\nyb = y_train[start_i:end_i]\r\n\r\nNow, we can do these two steps together:\r\nxb,yb = train_ds[i*bs : i*bs+bs]\r\n\r\nmodel, opt = get_model()\r\n\r\nfor epoch in range(epochs):\r\n    for i in range((n - 1) // bs + 1):\r\n        xb, yb = train_ds[i * bs: i * bs + bs]\r\n        pred = model(xb)\r\n        loss = loss_func(pred, yb)\r\n\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(0.0826, grad_fn=<NllLossBackward0>)\r\n\r\nRefactor using DataLoader\u00b6\r\nPyTorch\u2019s DataLoader is responsible for managing batches. You can\r\ncreate a DataLoader from any Dataset. DataLoader makes it easier\r\nto iterate over batches. Rather than having to use train_ds[i*bs : i*bs+bs],\r\nthe DataLoader gives us each minibatch automatically.", "mimetype": "text/plain", "start_char_idx": 16671, "end_char_idx": 20249, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a": {"__data__": {"id_": "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2302ec12-42e0-401f-a583-e8eda45ffa5c", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "a242579327bd95731bbf68c0db303d28bf2db86d921376a43440e53dcdb25490", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c4ef1d9-e443-4aa2-ae6f-86accede988f", "node_type": "1", "metadata": {}, "hash": "dda617f3728cd950e281cb9b3d31078e197e8eb4759d851f0a58e073d38d062d", "class_name": "RelatedNodeInfo"}}, "text": "You can\r\ncreate a DataLoader from any Dataset. DataLoader makes it easier\r\nto iterate over batches. Rather than having to use train_ds[i*bs : i*bs+bs],\r\nthe DataLoader gives us each minibatch automatically.\r\nfrom torch.utils.data import DataLoader\r\n\r\ntrain_ds = TensorDataset(x_train, y_train)\r\ntrain_dl = DataLoader(train_ds, batch_size=bs)\r\n\r\nPreviously, our loop iterated over batches (xb, yb) like this:\r\nfor i in range((n-1)//bs + 1):\r\n    xb,yb = train_ds[i*bs : i*bs+bs]\r\n    pred = model(xb)\r\n\r\nNow, our loop is much cleaner, as (xb, yb) are loaded automatically from the data loader:\r\nfor xb,yb in train_dl:\r\n    pred = model(xb)\r\n\r\nmodel, opt = get_model()\r\n\r\nfor epoch in range(epochs):\r\n    for xb, yb in train_dl:\r\n        pred = model(xb)\r\n        loss = loss_func(pred, yb)\r\n\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\nprint(loss_func(model(xb), yb))\r\n\r\ntensor(0.0818, grad_fn=<NllLossBackward0>)\r\n\r\nThanks to PyTorch\u2019s nn.Module, nn.Parameter, Dataset, and DataLoader,\r\nour training loop is now dramatically smaller and easier to understand. Let\u2019s\r\nnow try to add the basic features necessary to create effective models in practice.\r\nAdd validation\u00b6\r\nIn section 1, we were just trying to get a reasonable training loop set up for\r\nuse on our training data.  In reality, you always should also have\r\na validation set, in order\r\nto identify if you are overfitting.\r\nShuffling the training data is\r\nimportant\r\nto prevent correlation between batches and overfitting. On the other hand, the\r\nvalidation loss will be identical whether we shuffle the validation set or not.\r\nSince shuffling takes extra time, it makes no sense to shuffle the validation data.\r\nWe\u2019ll use a batch size for the validation set that is twice as large as\r\nthat for the training set. This is because the validation set does not\r\nneed backpropagation and thus takes less memory (it doesn\u2019t need to\r\nstore the gradients). We take advantage of this to use a larger batch\r\nsize and compute the loss more quickly.\r\ntrain_ds = TensorDataset(x_train, y_train)\r\ntrain_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\r\n\r\nvalid_ds = TensorDataset(x_valid, y_valid)\r\nvalid_dl = DataLoader(valid_ds, batch_size=bs * 2)\r\n\r\nWe will calculate and print the validation loss at the end of each epoch.\r\n(Note that we always call model.train() before training, and model.eval()\r\nbefore inference, because these are used by layers such as nn.BatchNorm2d\r\nand nn.Dropout to ensure appropriate behavior for these different phases.)\r\nmodel, opt = get_model()\r\n\r\nfor epoch in range(epochs):\r\n    model.train()\r\n    for xb, yb in train_dl:\r\n        pred = model(xb)\r\n        loss = loss_func(pred, yb)\r\n\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\n    model.eval()\r\n    with torch.no_grad():\r\n        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\r\n\r\n    print(epoch, valid_loss / len(valid_dl))\r\n\r\n0 tensor(0.3048)\r\n1 tensor(0.2872)\r\n\r\nCreate fit() and get_data()\u00b6\r\nWe\u2019ll now do a little refactoring of our own. Since we go through a similar\r\nprocess twice of calculating the loss for both the training set and the\r\nvalidation set, let\u2019s make that into its own function, loss_batch, which\r\ncomputes the loss for one batch.\r\nWe pass an optimizer in for the training set, and use it to perform\r\nbackprop.  For the validation set, we don\u2019t pass an optimizer, so the\r\nmethod doesn\u2019t perform backprop.\r\ndef loss_batch(model, loss_func, xb, yb, opt=None):\r\n    loss = loss_func(model(xb), yb)\r\n\r\n    if opt is not None:\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\n    return loss.item(), len(xb)\r\n\r\nfit runs the necessary operations to train our model and compute the\r\ntraining and validation losses for each epoch.", "mimetype": "text/plain", "start_char_idx": 20043, "end_char_idx": 23826, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c4ef1d9-e443-4aa2-ae6f-86accede988f": {"__data__": {"id_": "2c4ef1d9-e443-4aa2-ae6f-86accede988f", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "c63b9faa481e4875d78177027d9f9c018ff06490b0d35b462604b205d2c13ced", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4af45910-e0cc-4b75-9e08-244fe6521e48", "node_type": "1", "metadata": {}, "hash": "4eef542e14c9cb6ba9768a997f15cb863e1300c44ab583dc2713f62fab821682", "class_name": "RelatedNodeInfo"}}, "text": "Since we go through a similar\r\nprocess twice of calculating the loss for both the training set and the\r\nvalidation set, let\u2019s make that into its own function, loss_batch, which\r\ncomputes the loss for one batch.\r\nWe pass an optimizer in for the training set, and use it to perform\r\nbackprop.  For the validation set, we don\u2019t pass an optimizer, so the\r\nmethod doesn\u2019t perform backprop.\r\ndef loss_batch(model, loss_func, xb, yb, opt=None):\r\n    loss = loss_func(model(xb), yb)\r\n\r\n    if opt is not None:\r\n        loss.backward()\r\n        opt.step()\r\n        opt.zero_grad()\r\n\r\n    return loss.item(), len(xb)\r\n\r\nfit runs the necessary operations to train our model and compute the\r\ntraining and validation losses for each epoch.\r\nimport numpy as np\r\n\r\ndef fit(epochs, model, loss_func, opt, train_dl, valid_dl):\r\n    for epoch in range(epochs):\r\n        model.train()\r\n        for xb, yb in train_dl:\r\n            loss_batch(model, loss_func, xb, yb, opt)\r\n\r\n        model.eval()\r\n        with torch.no_grad():\r\n            losses, nums = zip(\r\n                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\r\n            )\r\n        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\r\n\r\n        print(epoch, val_loss)\r\n\r\nget_data returns dataloaders for the training and validation sets.\r\ndef get_data(train_ds, valid_ds, bs):\r\n    return (\r\n        DataLoader(train_ds, batch_size=bs, shuffle=True),\r\n        DataLoader(valid_ds, batch_size=bs * 2),\r\n    )\r\n\r\nNow, our whole process of obtaining the data loaders and fitting the\r\nmodel can be run in 3 lines of code:\r\ntrain_dl, valid_dl = get_data(train_ds, valid_ds, bs)\r\nmodel, opt = get_model()\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.2939354367017746\r\n1 0.3258970756947994\r\n\r\nYou can use these basic 3 lines of code to train a wide variety of models.\r\nLet\u2019s see if we can use them to train a convolutional neural network (CNN)!\r\nSwitch to CNN\u00b6\r\nWe are now going to build our neural network with three convolutional layers.\r\nBecause none of the functions in the previous section assume anything about\r\nthe model form, we\u2019ll be able to use them to train a CNN without any modification.\r\nWe will use PyTorch\u2019s predefined\r\nConv2d class\r\nas our convolutional layer. We define a CNN with 3 convolutional layers.\r\nEach convolution is followed by a ReLU.  At the end, we perform an\r\naverage pooling.  (Note that view is PyTorch\u2019s version of Numpy\u2019s\r\nreshape)\r\nclass Mnist_CNN(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\r\n        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\r\n        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\r\n\r\n    def forward(self, xb):\r\n        xb = xb.view(-1, 1, 28, 28)\r\n        xb = F.relu(self.conv1(xb))\r\n        xb = F.relu(self.conv2(xb))\r\n        xb = F.relu(self.conv3(xb))\r\n        xb = F.avg_pool2d(xb, 4)\r\n        return xb.view(-1, xb.size(1))\r\n\r\nlr = 0.1\r\n\r\nMomentum is a variation on\r\nstochastic gradient descent that takes previous updates into account as well\r\nand generally leads to faster training.\r\nmodel = Mnist_CNN()\r\nopt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\r\n\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.3646130460739136\r\n1 0.26228193019628526\r\n\r\nUsing nn.Sequential\u00b6\r\ntorch.nn has another handy class we can use to simplify our code:\r\nSequential .\r\nA Sequential object runs each of the modules contained within it, in a\r\nsequential manner. This is a simpler way of writing our neural network.\r\nTo take advantage of this, we need to be able to easily define a\r\ncustom layer from a given function.  For instance, PyTorch doesn\u2019t\r\nhave a view layer, and we need to create one for our network. Lambda\r\nwill create a layer that we can then use when defining a network with\r\nSequential.", "mimetype": "text/plain", "start_char_idx": 23100, "end_char_idx": 26994, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4af45910-e0cc-4b75-9e08-244fe6521e48": {"__data__": {"id_": "4af45910-e0cc-4b75-9e08-244fe6521e48", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c4ef1d9-e443-4aa2-ae6f-86accede988f", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "33016b007c308d18df6df067bab390332de1c8044f47dfa439c65745b4feb6aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18fcb37a-0626-46dc-ba3a-14926ba7fecc", "node_type": "1", "metadata": {}, "hash": "7b996d3425ca31b152b9dc06ba819c0510a576e6716888b91beab0fdcf95b9e2", "class_name": "RelatedNodeInfo"}}, "text": "model = Mnist_CNN()\r\nopt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\r\n\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.3646130460739136\r\n1 0.26228193019628526\r\n\r\nUsing nn.Sequential\u00b6\r\ntorch.nn has another handy class we can use to simplify our code:\r\nSequential .\r\nA Sequential object runs each of the modules contained within it, in a\r\nsequential manner. This is a simpler way of writing our neural network.\r\nTo take advantage of this, we need to be able to easily define a\r\ncustom layer from a given function.  For instance, PyTorch doesn\u2019t\r\nhave a view layer, and we need to create one for our network. Lambda\r\nwill create a layer that we can then use when defining a network with\r\nSequential.\r\nclass Lambda(nn.Module):\r\n    def __init__(self, func):\r\n        super().__init__()\r\n        self.func = func\r\n\r\n    def forward(self, x):\r\n        return self.func(x)\r\n\r\n\r\ndef preprocess(x):\r\n    return x.view(-1, 1, 28, 28)\r\n\r\nThe model created with Sequential is simple:\r\nmodel = nn.Sequential(\r\n    Lambda(preprocess),\r\n    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.AvgPool2d(4),\r\n    Lambda(lambda x: x.view(x.size(0), -1)),\r\n)\r\n\r\nopt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\r\n\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.3330025281429291\r\n1 0.22993727023601532\r\n\r\nWrapping DataLoader\u00b6\r\nOur CNN is fairly concise, but it only works with MNIST, because:\r\n\r\nIt assumes the input is a 28*28 long vector\r\nIt assumes that the final CNN grid size is 4*4 (since that\u2019s the average pooling kernel size we used)\r\n\r\n\r\nIt assumes the input is a 28*28 long vector\r\nIt assumes that the final CNN grid size is 4*4 (since that\u2019s the average pooling kernel size we used)\r\nLet\u2019s get rid of these two assumptions, so our model works with any 2d\r\nsingle channel image. First, we can remove the initial Lambda layer by\r\nmoving the data preprocessing into a generator:\r\ndef preprocess(x, y):\r\n    return x.view(-1, 1, 28, 28), y\r\n\r\n\r\nclass WrappedDataLoader:\r\n    def __init__(self, dl, func):\r\n        self.dl = dl\r\n        self.func = func\r\n\r\n    def __len__(self):\r\n        return len(self.dl)\r\n\r\n    def __iter__(self):\r\n        for b in self.dl:\r\n            yield (self.func(*b))\r\n\r\ntrain_dl, valid_dl = get_data(train_ds, valid_ds, bs)\r\ntrain_dl = WrappedDataLoader(train_dl, preprocess)\r\nvalid_dl = WrappedDataLoader(valid_dl, preprocess)\r\n\r\nNext, we can replace nn.AvgPool2d with nn.AdaptiveAvgPool2d, which\r\nallows us to define the size of the output tensor we want, rather than\r\nthe input tensor we have. As a result, our model will work with any\r\nsize input.\r\nmodel = nn.Sequential(\r\n    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\r\n    nn.ReLU(),\r\n    nn.AdaptiveAvgPool2d(1),\r\n    Lambda(lambda x: x.view(x.size(0), -1)),\r\n)\r\n\r\nopt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\r\n\r\nLet\u2019s try it out:\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.3212135115623474\r\n1 0.21439074140787123\r\n\r\nUsing your GPU\u00b6\r\nIf you\u2019re lucky enough to have access to a CUDA-capable GPU (you can\r\nrent one for about $0.50/hour from most cloud providers) you can\r\nuse it to speed up your code.", "mimetype": "text/plain", "start_char_idx": 26274, "end_char_idx": 29769, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18fcb37a-0626-46dc-ba3a-14926ba7fecc": {"__data__": {"id_": "18fcb37a-0626-46dc-ba3a-14926ba7fecc", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4af45910-e0cc-4b75-9e08-244fe6521e48", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "3589ce23c6907dce6006992eecc303c44ad430bed41319f32166723b11345748", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8407cd9a-84c0-47bb-8e34-3605577eb0cb", "node_type": "1", "metadata": {}, "hash": "e97ca5041d8d4ee976d564af15a9e074dbb0c566acff76e640a4e6cba5396adb", "class_name": "RelatedNodeInfo"}}, "text": "First check that your GPU is working in\r\nPytorch:\r\nprint(torch.cuda.is_available())\r\n\r\nTrue\r\n\r\nAnd then create a device object for it:\r\ndev = torch.device(\r\n    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n\r\nLet\u2019s update preprocess to move batches to the GPU:\r\ndef preprocess(x, y):\r\n    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\r\n\r\n\r\ntrain_dl, valid_dl = get_data(train_ds, valid_ds, bs)\r\ntrain_dl = WrappedDataLoader(train_dl, preprocess)\r\nvalid_dl = WrappedDataLoader(valid_dl, preprocess)\r\n\r\nFinally, we can move our model to the GPU.\r\nmodel.to(dev)\r\nopt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\r\n\r\nYou should find it runs faster now:\r\nfit(epochs, model, loss_func, opt, train_dl, valid_dl)\r\n\r\n0 0.18051417416334153\r\n1 0.16745494151115417\r\n\r\nClosing thoughts\u00b6\r\nWe now have a general data pipeline and training loop which you can use for\r\ntraining many types of models using Pytorch. To see how simple training a model\r\ncan now be, take a look at the mnist_sample notebook.\r\nOf course, there are many things you\u2019ll want to add, such as data augmentation,\r\nhyperparameter tuning, monitoring training, transfer learning, and so forth.\r\nThese features are available in the fastai library, which has been developed\r\nusing the same design approach shown in this tutorial, providing a natural\r\nnext step for practitioners looking to take their models further.\r\nWe promised at the start of this tutorial we\u2019d explain through example each of\r\ntorch.nn, torch.optim, Dataset, and DataLoader. So let\u2019s summarize\r\nwhat we\u2019ve seen:\r\ntorch.nn:\r\nModule: creates a callable which behaves like a function, but can also\r\ncontain state(such as neural net layer weights). It knows what Parameter (s) it\r\ncontains and can zero all their gradients, loop through them for weight updates, etc.\r\nParameter: a wrapper for a tensor that tells a Module that it has weights\r\nthat need updating during backprop. Only tensors with the requires_grad attribute set are updated\r\nfunctional: a module(usually imported into the F namespace by convention)\r\nwhich contains activation functions, loss functions, etc, as well as non-stateful\r\nversions of layers such as convolutional and linear layers.\r\ntorch.optim: Contains optimizers such as SGD, which update the weights\r\nof Parameter during the backward step\r\nDataset: An abstract interface of objects with a __len__ and a __getitem__,\r\nincluding classes provided with Pytorch such as TensorDataset\r\nDataLoader: Takes any Dataset and creates an iterator which returns batches of data.\r\nTotal running time of the script: ( 0 minutes  36.362 seconds)\r\nDownload Python source code: nn_tutorial.py\r\nDownload Jupyter notebook: nn_tutorial.ipynb\r\nGallery generated by Sphinx-Gallery \r\n\r\nsource: https://pytorch.org/tutorials/intermediate/nlp_from_scratch_index.html \r\ncontent: \r\n\r\nNLP from Scratch\u00b6\r\nIn these three-part series you will build and train\r\na basic character-level Recurrent Neural Network (RNN) to classify words.\r\nYou will learn:\r\nHow to construct Recurrent Neural Networks from scratch\r\nEssential data handling techniques for NLP\r\nHow to train an RNN to identify the language origin of words.\r\nBefore you begin, we recommend that you review the following:\r\nPyTorch Learn the Basics series\r\nHow to install PyTorch\r\nLearn how to use an RNN to classify names into their language of origin.\r\n Code\r\nExpand the RNN we created in Part 1 to generate names from languages.\r\n Code\r\nCreate a sequence-to-sequence model that can translate your text from French\r\nto English.\r\n Code \r\n\r\nsource: https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html \r\ncontent: \r\n\r\nVisualizing Models, Data, and Training with TensorBoard\u00b6\r\nIn the 60 Minute Blitz,\r\nwe show you how to load in data,\r\nfeed it through a model we define as a subclass of nn.Module,\r\ntrain this model on training data, and test it on test data.\r\nTo see what\u2019s happening, we print out some statistics as the model\r\nis training to get a sense for whether training is progressing.\r\nHowever, we can do much better than that: PyTorch integrates with\r\nTensorBoard, a tool designed for visualizing the results of neural\r\nnetwork training runs. This tutorial illustrates some of its\r\nfunctionality, using the\r\nFashion-MNIST dataset\r\nwhich can be read into PyTorch using torchvision.datasets.\r\nIn this tutorial, we\u2019ll learn how to:\r\nRead in data and with appropriate transforms (nearly identical to the prior tutorial).\r\nSet up TensorBoard.\r\nWrite to TensorBoard.\r\nInspect a model architecture using TensorBoard.", "mimetype": "text/plain", "start_char_idx": 29770, "end_char_idx": 34299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8407cd9a-84c0-47bb-8e34-3605577eb0cb": {"__data__": {"id_": "8407cd9a-84c0-47bb-8e34-3605577eb0cb", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18fcb37a-0626-46dc-ba3a-14926ba7fecc", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "35962d734e574d1a6befe75df9f67412758572671c8a6948dae3aad677fa3ca1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fd851d4a-b424-4e30-a021-f3305816aa79", "node_type": "1", "metadata": {}, "hash": "373fc63bd764005cfea9f1e3464fbed47e4860fc38d139edea3abeb4b8d03f14", "class_name": "RelatedNodeInfo"}}, "text": "To see what\u2019s happening, we print out some statistics as the model\r\nis training to get a sense for whether training is progressing.\r\nHowever, we can do much better than that: PyTorch integrates with\r\nTensorBoard, a tool designed for visualizing the results of neural\r\nnetwork training runs. This tutorial illustrates some of its\r\nfunctionality, using the\r\nFashion-MNIST dataset\r\nwhich can be read into PyTorch using torchvision.datasets.\r\nIn this tutorial, we\u2019ll learn how to:\r\nRead in data and with appropriate transforms (nearly identical to the prior tutorial).\r\nSet up TensorBoard.\r\nWrite to TensorBoard.\r\nInspect a model architecture using TensorBoard.\r\nUse TensorBoard to create interactive versions of the visualizations we created in last tutorial, with less code\r\nSpecifically, on point #5, we\u2019ll see:\r\nA couple of ways to inspect our training data\r\nHow to track our model\u2019s performance as it trains\r\nHow to assess our model\u2019s performance once it is trained.\r\nWe\u2019ll begin with similar boilerplate code as in the CIFAR-10 tutorial:\r\n# imports\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nimport torch\r\nimport torchvision\r\nimport torchvision.transforms as transforms\r\n\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\n\r\n# transforms\r\ntransform = transforms.Compose(\r\n    [transforms.ToTensor(),\r\n    transforms.Normalize((0.5,), (0.5,))])\r\n\r\n# datasets\r\ntrainset = torchvision.datasets.FashionMNIST('./data',\r\n    download=True,\r\n    train=True,\r\n    transform=transform)\r\ntestset = torchvision.datasets.FashionMNIST('./data',\r\n    download=True,\r\n    train=False,\r\n    transform=transform)\r\n\r\n# dataloaders\r\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\r\n                                        shuffle=True, num_workers=2)\r\n\r\n\r\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\r\n                                        shuffle=False, num_workers=2)\r\n\r\n# constant for classes\r\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\r\n\r\n# helper function to show an image\r\n# (used in the `plot_classes_preds` function below)\r\ndef matplotlib_imshow(img, one_channel=False):\r\n    if one_channel:\r\n        img = img.mean(dim=0)\r\n    img = img / 2 + 0.5     # unnormalize\r\n    npimg = img.numpy()\r\n    if one_channel:\r\n        plt.imshow(npimg, cmap=\"Greys\")\r\n    else:\r\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n\r\nWe\u2019ll define a similar model architecture from that tutorial, making only\r\nminor modifications to account for the fact that the images are now\r\none channel instead of three and 28x28 instead of 32x32:\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv2d(1, 6, 5)\r\n        self.pool = nn.MaxPool2d(2, 2)\r\n        self.conv2 = nn.Conv2d(6, 16, 5)\r\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\r\n        self.fc2 = nn.Linear(120, 84)\r\n        self.fc3 = nn.Linear(84, 10)\r\n\r\n    def forward(self, x):\r\n        x = self.pool(F.relu(self.conv1(x)))\r\n        x = self.pool(F.relu(self.conv2(x)))\r\n        x = x.view(-1, 16 * 4 * 4)\r\n        x = F.relu(self.fc1(x))\r\n        x = F.relu(self.fc2(x))\r\n        x = self.fc3(x)\r\n        return x\r\n\r\n\r\nnet = Net()\r\n\r\nWe\u2019ll define the same optimizer and criterion from before:\r\ncriterion = nn.CrossEntropyLoss()\r\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\r\n\r\n1. TensorBoard setup\u00b6\r\nNow we\u2019ll set up TensorBoard, importing tensorboard from torch.utils and defining a\r\nSummaryWriter, our key object for writing information to TensorBoard.\r\nfrom torch.utils.tensorboard import SummaryWriter\r\n\r\n# default `log_dir` is \"runs\" - we'll be more specific here\r\nwriter = SummaryWriter('runs/fashion_mnist_experiment_1')\r\n\r\nNote that this line alone creates a runs/fashion_mnist_experiment_1\r\nfolder.\r\n2. Writing to TensorBoard\u00b6\r\nNow let\u2019s write an image to our TensorBoard - specifically, a grid -\r\nusing make_grid.", "mimetype": "text/plain", "start_char_idx": 33642, "end_char_idx": 37649, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fd851d4a-b424-4e30-a021-f3305816aa79": {"__data__": {"id_": "fd851d4a-b424-4e30-a021-f3305816aa79", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8407cd9a-84c0-47bb-8e34-3605577eb0cb", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "00f3ee3290ab3aa9a08a292394bac33c48b5c502639336212b3d29edc7274d64", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "195e5394-e1ed-4853-bfc1-ed656d7cf660", "node_type": "1", "metadata": {}, "hash": "c42840d4c438da2a5955d561adf3017df69f9edb9e38e1cb857641507673205f", "class_name": "RelatedNodeInfo"}}, "text": "TensorBoard setup\u00b6\r\nNow we\u2019ll set up TensorBoard, importing tensorboard from torch.utils and defining a\r\nSummaryWriter, our key object for writing information to TensorBoard.\r\nfrom torch.utils.tensorboard import SummaryWriter\r\n\r\n# default `log_dir` is \"runs\" - we'll be more specific here\r\nwriter = SummaryWriter('runs/fashion_mnist_experiment_1')\r\n\r\nNote that this line alone creates a runs/fashion_mnist_experiment_1\r\nfolder.\r\n2. Writing to TensorBoard\u00b6\r\nNow let\u2019s write an image to our TensorBoard - specifically, a grid -\r\nusing make_grid.\r\n# get some random training images\r\ndataiter = iter(trainloader)\r\nimages, labels = next(dataiter)\r\n\r\n# create grid of images\r\nimg_grid = torchvision.utils.make_grid(images)\r\n\r\n# show images\r\nmatplotlib_imshow(img_grid, one_channel=True)\r\n\r\n# write to tensorboard\r\nwriter.add_image('four_fashion_mnist_images', img_grid)\r\n\r\nNow running\r\ntensorboard --logdir=runs\r\n\r\nfrom the command line and then navigating to http://localhost:6006\r\nshould show the following.\r\nNow you know how to use TensorBoard! This example, however, could be\r\ndone in a Jupyter Notebook - where TensorBoard really excels is in\r\ncreating interactive visualizations. We\u2019ll cover one of those next,\r\nand several more by the end of the tutorial.\r\n3. Inspect the model using TensorBoard\u00b6\r\nOne of TensorBoard\u2019s strengths is its ability to visualize complex model\r\nstructures. Let\u2019s visualize the model we built.\r\nwriter.add_graph(net, images)\r\nwriter.close()\r\n\r\nNow upon refreshing TensorBoard you should see a \u201cGraphs\u201d tab that\r\nlooks like this:\r\nGo ahead and double click on \u201cNet\u201d to see it expand, seeing a\r\ndetailed view of the individual operations that make up the model.\r\nTensorBoard has a very handy feature for visualizing high dimensional\r\ndata such as image data in a lower dimensional space; we\u2019ll cover this\r\nnext.\r\n4. Adding a \u201cProjector\u201d to TensorBoard\u00b6\r\nWe can visualize the lower dimensional representation of higher\r\ndimensional data via the add_embedding method\r\n# helper function\r\ndef select_n_random(data, labels, n=100):\r\n    '''\r\n    Selects n random datapoints and their corresponding labels from a dataset\r\n    '''\r\n    assert len(data) == len(labels)\r\n\r\n    perm = torch.randperm(len(data))\r\n    return data[perm][:n], labels[perm][:n]\r\n\r\n# select random images and their target indices\r\nimages, labels = select_n_random(trainset.data, trainset.targets)\r\n\r\n# get the class labels for each image\r\nclass_labels = [classes[lab] for lab in labels]\r\n\r\n# log embeddings\r\nfeatures = images.view(-1, 28 * 28)\r\nwriter.add_embedding(features,\r\n                    metadata=class_labels,\r\n                    label_img=images.unsqueeze(1))\r\nwriter.close()\r\n\r\nNow in the \u201cProjector\u201d tab of TensorBoard, you can see these 100\r\nimages - each of which is 784 dimensional - projected down into three\r\ndimensional space. Furthermore, this is interactive: you can click\r\nand drag to rotate the three dimensional projection. Finally, a couple\r\nof tips to make the visualization easier to see: select \u201ccolor: label\u201d\r\non the top left, as well as enabling \u201cnight mode\u201d, which will make the\r\nimages easier to see since their background is white:\r\nNow we\u2019ve thoroughly inspected our data, let\u2019s show how TensorBoard\r\ncan make tracking model training and evaluation clearer, starting with\r\ntraining.\r\n5. Tracking model training with TensorBoard\u00b6\r\nIn the previous example, we simply printed the model\u2019s running loss\r\nevery 2000 iterations. Now, we\u2019ll instead log the running loss to\r\nTensorBoard, along with a view into the predictions the model is\r\nmaking via the plot_classes_preds function.\r\n# helper functions\r\n\r\ndef images_to_probs(net, images):\r\n    '''\r\n    Generates predictions and corresponding probabilities from a trained\r\n    network and a list of images\r\n    '''\r\n    output = net(images)\r\n    # convert output probabilities to predicted class\r\n    _, preds_tensor = torch.max(output, 1)\r\n    preds = np.squeeze(preds_tensor.numpy())\r\n    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\r\n\r\n\r\ndef plot_classes_preds(net, images, labels):\r\n    '''\r\n    Generates matplotlib Figure using a trained network, along with images\r\n    and labels from a batch, that shows the network's top prediction along\r\n    with its probability, alongside the actual label, coloring this\r\n    information based on whether the prediction was correct or not.\r\n    Uses the \"images_to_probs\" function.\r\n    '''", "mimetype": "text/plain", "start_char_idx": 37106, "end_char_idx": 41546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "195e5394-e1ed-4853-bfc1-ed656d7cf660": {"__data__": {"id_": "195e5394-e1ed-4853-bfc1-ed656d7cf660", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fd851d4a-b424-4e30-a021-f3305816aa79", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "b546280222bea399e0ee826c7db9cd37c1770921807179749efb1bf2b048e83a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6", "node_type": "1", "metadata": {}, "hash": "4bd462b9a63e0c5594785c434a9408c08c1ab1eeb4e9071ffcfd424962aef001", "class_name": "RelatedNodeInfo"}}, "text": "# helper functions\r\n\r\ndef images_to_probs(net, images):\r\n    '''\r\n    Generates predictions and corresponding probabilities from a trained\r\n    network and a list of images\r\n    '''\r\n    output = net(images)\r\n    # convert output probabilities to predicted class\r\n    _, preds_tensor = torch.max(output, 1)\r\n    preds = np.squeeze(preds_tensor.numpy())\r\n    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\r\n\r\n\r\ndef plot_classes_preds(net, images, labels):\r\n    '''\r\n    Generates matplotlib Figure using a trained network, along with images\r\n    and labels from a batch, that shows the network's top prediction along\r\n    with its probability, alongside the actual label, coloring this\r\n    information based on whether the prediction was correct or not.\r\n    Uses the \"images_to_probs\" function.\r\n    '''\r\n    preds, probs = images_to_probs(net, images)\r\n    # plot the images in the batch, along with predicted and true labels\r\n    fig = plt.figure(figsize=(12, 48))\r\n    for idx in np.arange(4):\r\n        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\r\n        matplotlib_imshow(images[idx], one_channel=True)\r\n        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\r\n            classes[preds[idx]],\r\n            probs[idx] * 100.0,\r\n            classes[labels[idx]]),\r\n                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\r\n    return fig\r\n\r\nFinally, let\u2019s train the model using the same model training code from\r\nthe prior tutorial, but writing results to TensorBoard every 1000\r\nbatches instead of printing to console; this is done using the\r\nadd_scalar\r\nfunction.\r\nIn addition, as we train, we\u2019ll generate an image showing the model\u2019s\r\npredictions vs. the actual results on the four images included in that\r\nbatch.\r\nrunning_loss = 0.0\r\nfor epoch in range(1):  # loop over the dataset multiple times\r\n\r\n    for i, data in enumerate(trainloader, 0):\r\n\r\n        # get the inputs; data is a list of [inputs, labels]\r\n        inputs, labels = data\r\n\r\n        # zero the parameter gradients\r\n        optimizer.zero_grad()\r\n\r\n        # forward + backward + optimize\r\n        outputs = net(inputs)\r\n        loss = criterion(outputs, labels)\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n        running_loss += loss.item()\r\n        if i % 1000 == 999:    # every 1000 mini-batches...\r\n\r\n            # ...log the running loss\r\n            writer.add_scalar('training loss',\r\n                            running_loss / 1000,\r\n                            epoch * len(trainloader) + i)\r\n\r\n            # ...log a Matplotlib Figure showing the model's predictions on a\r\n            # random mini-batch\r\n            writer.add_figure('predictions vs. actuals',\r\n                            plot_classes_preds(net, inputs, labels),\r\n                            global_step=epoch * len(trainloader) + i)\r\n            running_loss = 0.0\r\nprint('Finished Training')\r\n\r\nYou can now look at the scalars tab to see the running loss plotted\r\nover the 15,000 iterations of training:\r\nIn addition, we can look at the predictions the model made on\r\narbitrary batches throughout learning. See the \u201cImages\u201d tab and scroll\r\ndown under the \u201cpredictions vs. actuals\u201d visualization to see this;\r\nthis shows us that, for example, after just 3000 training iterations,\r\nthe model was already able to distinguish between visually distinct\r\nclasses such as shirts, sneakers, and coats, though it isn\u2019t as\r\nconfident as it becomes later on in training:\r\nIn the prior tutorial, we looked at per-class accuracy once the model\r\nhad been trained; here, we\u2019ll use TensorBoard to plot precision-recall\r\ncurves (good explanation\r\nhere)\r\nfor each class.\r\n6.", "mimetype": "text/plain", "start_char_idx": 40710, "end_char_idx": 44408, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6": {"__data__": {"id_": "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "195e5394-e1ed-4853-bfc1-ed656d7cf660", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "c89656ece9d2350bb8afd1ca4183a8fed168ef49655cc04c6a77df9c72975313", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5538188-352c-42a8-9b6e-8ab697391766", "node_type": "1", "metadata": {}, "hash": "9ae9a26c89ac3fa99c91fe0125f9fdd1f8e77b0304ccb75276dbb6e35d0b5f74", "class_name": "RelatedNodeInfo"}}, "text": "See the \u201cImages\u201d tab and scroll\r\ndown under the \u201cpredictions vs. actuals\u201d visualization to see this;\r\nthis shows us that, for example, after just 3000 training iterations,\r\nthe model was already able to distinguish between visually distinct\r\nclasses such as shirts, sneakers, and coats, though it isn\u2019t as\r\nconfident as it becomes later on in training:\r\nIn the prior tutorial, we looked at per-class accuracy once the model\r\nhad been trained; here, we\u2019ll use TensorBoard to plot precision-recall\r\ncurves (good explanation\r\nhere)\r\nfor each class.\r\n6. Assessing trained models with TensorBoard\u00b6\r\n# 1. gets the probability predictions in a test_size x num_classes Tensor\r\n# 2. gets the preds in a test_size Tensor\r\n# takes ~10 seconds to run\r\nclass_probs = []\r\nclass_label = []\r\nwith torch.no_grad():\r\n    for data in testloader:\r\n        images, labels = data\r\n        output = net(images)\r\n        class_probs_batch = [F.softmax(el, dim=0) for el in output]\r\n\r\n        class_probs.append(class_probs_batch)\r\n        class_label.append(labels)\r\n\r\ntest_probs = torch.cat([torch.stack(batch) for batch in class_probs])\r\ntest_label = torch.cat(class_label)\r\n\r\n# helper function\r\ndef add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\r\n    '''\r\n    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\r\n    precision-recall curve\r\n    '''\r\n    tensorboard_truth = test_label == class_index\r\n    tensorboard_probs = test_probs[:, class_index]\r\n\r\n    writer.add_pr_curve(classes[class_index],\r\n                        tensorboard_truth,\r\n                        tensorboard_probs,\r\n                        global_step=global_step)\r\n    writer.close()\r\n\r\n# plot all the pr curves\r\nfor i in range(len(classes)):\r\n    add_pr_curve_tensorboard(i, test_probs, test_label)\r\n\r\nYou will now see a \u201cPR Curves\u201d tab that contains the precision-recall\r\ncurves for each class. Go ahead and poke around; you\u2019ll see that on\r\nsome classes the model has nearly 100% \u201carea under the curve\u201d,\r\nwhereas on others this area is lower:\r\nAnd that\u2019s an intro to TensorBoard and PyTorch\u2019s integration with it.\r\nOf course, you could do everything TensorBoard does in your Jupyter\r\nNotebook, but with TensorBoard, you gets visuals that are interactive\r\nby default. \r\n\r\nsource: https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html \r\ncontent: \r\n\r\nNote\r\nClick here\r\nto download the full example code\r\nA guide on good usage of non_blocking and pin_memory() in PyTorch\u00b6\r\nAuthor: Vincent Moens\r\nIntroduction\u00b6\r\nTransferring data from the CPU to the GPU is fundamental in many PyTorch applications.\r\nIt\u2019s crucial for users to understand the most effective tools and options available for moving data between devices.\r\nThis tutorial examines two key methods for device-to-device data transfer in PyTorch:\r\npin_memory() and to() with the non_blocking=True option.\r\nWhat you will learn\u00b6\r\nOptimizing the transfer of tensors from the CPU to the GPU can be achieved through asynchronous transfers and memory\r\npinning. However, there are important considerations:\r\nUsing tensor.pin_memory().to(device, non_blocking=True) can be up to twice as slow as a straightforward tensor.to(device).\r\nGenerally, tensor.to(device, non_blocking=True) is an effective choice for enhancing transfer speed.\r\nWhile cpu_tensor.to(\"cuda\", non_blocking=True).mean() executes correctly, attempting\r\ncuda_tensor.to(\"cpu\", non_blocking=True).mean() will result in erroneous outputs.\r\nPreamble\u00b6\r\nThe performance reported in this tutorial are conditioned on the system used to build the tutorial.\r\nAlthough the conclusions are applicable across different systems, the specific observations may vary slightly\r\ndepending on the hardware available, especially on older hardware.\r\nThe primary objective of this tutorial is to offer a theoretical framework for understanding CPU to GPU data transfers.\r\nHowever, any design decisions should be tailored to individual cases and guided by benchmarked throughput measurements,\r\nas well as the specific requirements of the task at hand.\r\nimport torch\r\n\r\nassert torch.cuda.is_available(), \"A cuda device is required to run this tutorial\"\r\n\r\nThis tutorial requires tensordict to be installed. If you don\u2019t have tensordict in your environment yet, install it\r\nby running the following command in a separate cell:\r\n# Install tensordict with the following command\r\n!pip3 install tensordict\r\n\r\nWe start by outlining the theory surrounding these concepts, and then move to concrete test examples of the features.\r\nBackground\u00b6\r\nMemory management basics\u00b6\r\nWhen one creates a CPU tensor in PyTorch, the content of this tensor needs to be placed\r\nin memory. The memory we talk about here is a rather complex concept worth looking at carefully.", "mimetype": "text/plain", "start_char_idx": 43859, "end_char_idx": 48603, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5538188-352c-42a8-9b6e-8ab697391766": {"__data__": {"id_": "b5538188-352c-42a8-9b6e-8ab697391766", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "1101e92d712c0c4f0e3dd6740152fab3711cce15ce22338fcb8df494e5928812", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66f4cf08-6189-4075-9bc4-12232900e7ba", "node_type": "1", "metadata": {}, "hash": "6cdbc78b5ccf2d9f3bc6a173ae35b81de6df4442344ea1c954b5a1c929a84157", "class_name": "RelatedNodeInfo"}}, "text": "The primary objective of this tutorial is to offer a theoretical framework for understanding CPU to GPU data transfers.\r\nHowever, any design decisions should be tailored to individual cases and guided by benchmarked throughput measurements,\r\nas well as the specific requirements of the task at hand.\r\nimport torch\r\n\r\nassert torch.cuda.is_available(), \"A cuda device is required to run this tutorial\"\r\n\r\nThis tutorial requires tensordict to be installed. If you don\u2019t have tensordict in your environment yet, install it\r\nby running the following command in a separate cell:\r\n# Install tensordict with the following command\r\n!pip3 install tensordict\r\n\r\nWe start by outlining the theory surrounding these concepts, and then move to concrete test examples of the features.\r\nBackground\u00b6\r\nMemory management basics\u00b6\r\nWhen one creates a CPU tensor in PyTorch, the content of this tensor needs to be placed\r\nin memory. The memory we talk about here is a rather complex concept worth looking at carefully.\r\nWe distinguish two types of memory that are handled by the Memory Management Unit: the RAM (for simplicity)\r\nand the swap space on disk (which may or may not be the hard drive). Together, the available space in disk and RAM (physical memory)\r\nmake up the virtual memory, which is an abstraction of the total resources available.\r\nIn short, the virtual memory makes it so that the available space is larger than what can be found on RAM in isolation\r\nand creates the illusion that the main memory is larger than it actually is.\r\nIn normal circumstances, a regular CPU tensor is pageable which means that it is divided in blocks called pages that\r\ncan live anywhere in the virtual memory (both in RAM or on disk). As mentioned earlier, this has the advantage that\r\nthe memory seems larger than what the main memory actually is.\r\nTypically, when a program accesses a page that is not in RAM, a \u201cpage fault\u201d occurs and the operating system (OS) then brings\r\nback this page into RAM (\u201cswap in\u201d or \u201cpage in\u201d).\r\nIn turn, the OS may have to swap out (or \u201cpage out\u201d) another page to make room for the new page.\r\nIn contrast to pageable memory, a pinned (or page-locked or non-pageable) memory is a type of memory that cannot\r\nbe swapped out to disk.\r\nIt allows for faster and more predictable access times, but has the downside that it is more limited than the\r\npageable memory (aka the main memory).\r\nCUDA and (non-)pageable memory\u00b6\r\nTo understand how CUDA copies a tensor from CPU to CUDA, let\u2019s consider the two scenarios above:\r\nIf the memory is page-locked, the device can access the memory directly in the main memory. The memory addresses are well\r\ndefined and functions that need to read these data can be significantly accelerated.\r\nIf the memory is pageable, all the pages will have to be brought to the main memory before being sent to the GPU.\r\nThis operation may take time and is less predictable than when executed on page-locked tensors.\r\nMore precisely, when CUDA sends pageable data from CPU to GPU, it must first create a page-locked copy of that data\r\nbefore making the transfer.\r\nAsynchronous vs. Synchronous Operations with non_blocking=True (CUDA cudaMemcpyAsync)\u00b6\r\nWhen executing a copy from a host (e.g., CPU) to a device (e.g., GPU), the CUDA toolkit offers modalities to do these\r\noperations synchronously or asynchronously with respect to the host.\r\nIn practice, when calling to(), PyTorch always makes a call to\r\ncudaMemcpyAsync.\r\nIf non_blocking=False (default), a cudaStreamSynchronize will be called after each and every cudaMemcpyAsync, making\r\nthe call to to() blocking in the main thread.\r\nIf non_blocking=True, no synchronization is triggered, and the main thread on the host is not blocked.\r\nTherefore, from the host perspective, multiple tensors can be sent to the device simultaneously,\r\nas the thread does not need to wait for one transfer to be completed to initiate the other.\r\nNote\r\nIn general, the transfer is blocking on the device side (even if it isn\u2019t on the host side):\r\nthe copy on the device cannot occur while another operation is being executed.\r\nHowever, in some advanced scenarios, a copy and a kernel execution can be done simultaneously on the GPU side.\r\nAs the following example will show, three requirements must be met to enable this:\r\nThe device must have at least one free DMA (Direct Memory Access) engine. Modern GPU architectures such as Volterra,\r\nTesla, or H100 devices have more than one DMA engine.\r\nThe transfer must be done on a separate, non-default cuda stream. In PyTorch, cuda streams can be handles using\r\nStream.\r\nThe source data must be in pinned memory.\r\nWe demonstrate this by running profiles on the following script.", "mimetype": "text/plain", "start_char_idx": 47608, "end_char_idx": 52293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66f4cf08-6189-4075-9bc4-12232900e7ba": {"__data__": {"id_": "66f4cf08-6189-4075-9bc4-12232900e7ba", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5538188-352c-42a8-9b6e-8ab697391766", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "9ae8dcced0a1eae4275047b85e2b44ce67f9f79e5ab0f6eac879933ee6bc37db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7bf5d248-bf26-4d2b-b4a4-867a5a070e89", "node_type": "1", "metadata": {}, "hash": "508ac8dd15480714ec27953b9d5d8d22025962751642c8000f4b244300515d41", "class_name": "RelatedNodeInfo"}}, "text": "Therefore, from the host perspective, multiple tensors can be sent to the device simultaneously,\r\nas the thread does not need to wait for one transfer to be completed to initiate the other.\r\nNote\r\nIn general, the transfer is blocking on the device side (even if it isn\u2019t on the host side):\r\nthe copy on the device cannot occur while another operation is being executed.\r\nHowever, in some advanced scenarios, a copy and a kernel execution can be done simultaneously on the GPU side.\r\nAs the following example will show, three requirements must be met to enable this:\r\nThe device must have at least one free DMA (Direct Memory Access) engine. Modern GPU architectures such as Volterra,\r\nTesla, or H100 devices have more than one DMA engine.\r\nThe transfer must be done on a separate, non-default cuda stream. In PyTorch, cuda streams can be handles using\r\nStream.\r\nThe source data must be in pinned memory.\r\nWe demonstrate this by running profiles on the following script.\r\nimport contextlib\r\n\r\nfrom torch.cuda import Stream\r\n\r\n\r\ns = Stream()\r\n\r\ntorch.manual_seed(42)\r\nt1_cpu_pinned = torch.randn(1024**2 * 5, pin_memory=True)\r\nt2_cpu_paged = torch.randn(1024**2 * 5, pin_memory=False)\r\nt3_cuda = torch.randn(1024**2 * 5, device=\"cuda:0\")\r\n\r\nassert torch.cuda.is_available()\r\ndevice = torch.device(\"cuda\", torch.cuda.current_device())\r\n\r\n\r\n# The function we want to profile\r\ndef inner(pinned: bool, streamed: bool):\r\n    with torch.cuda.stream(s) if streamed else contextlib.nullcontext():\r\n        if pinned:\r\n            t1_cuda = t1_cpu_pinned.to(device, non_blocking=True)\r\n        else:\r\n            t2_cuda = t2_cpu_paged.to(device, non_blocking=True)\r\n        t_star_cuda_h2d_event = s.record_event()\r\n    # This operation can be executed during the CPU to GPU copy if and only if the tensor is pinned and the copy is\r\n    #  done in the other stream\r\n    t3_cuda_mul = t3_cuda * t3_cuda * t3_cuda\r\n    t3_cuda_h2d_event = torch.cuda.current_stream().record_event()\r\n    t_star_cuda_h2d_event.synchronize()\r\n    t3_cuda_h2d_event.synchronize()\r\n\r\n\r\n# Our profiler: profiles the `inner` function and stores the results in a .json file\r\ndef benchmark_with_profiler(\r\n    pinned,\r\n    streamed,\r\n) -> None:\r\n    torch._C._profiler._set_cuda_sync_enabled_val(True)\r\n    wait, warmup, active = 1, 1, 2\r\n    num_steps = wait + warmup + active\r\n    rank = 0\r\n    with torch.profiler.profile(\r\n        activities=[\r\n            torch.profiler.ProfilerActivity.CPU,\r\n            torch.profiler.ProfilerActivity.CUDA,\r\n        ],\r\n        schedule=torch.profiler.schedule(\r\n            wait=wait, warmup=warmup, active=active, repeat=1, skip_first=1\r\n        ),\r\n    ) as prof:\r\n        for step_idx in range(1, num_steps + 1):\r\n            inner(streamed=streamed, pinned=pinned)\r\n            if rank is None or rank == 0:\r\n                prof.step()\r\n    prof.export_chrome_trace(f\"trace_streamed{int(streamed)}_pinned{int(pinned)}.json\")\r\n\r\nLoading these profile traces in chrome (chrome://tracing) shows the following results: first, let\u2019s see\r\nwhat happens if both the arithmetic operation on t3_cuda is executed after the pageable tensor is sent to GPU\r\nin the main stream:\r\nbenchmark_with_profiler(streamed=False, pinned=False)\r\n\r\nUsing a pinned tensor doesn\u2019t change the trace much, both operations are still executed consecutively:\r\nbenchmark_with_profiler(streamed=False, pinned=True)\r\n\r\nSending a pageable tensor to GPU on a separate stream is also a blocking operation:\r\nbenchmark_with_profiler(streamed=True, pinned=False)\r\n\r\nOnly pinned tensors copies to GPU on a separate stream overlap with another cuda kernel executed on\r\nthe main stream:\r\nbenchmark_with_profiler(streamed=True, pinned=True)\r\n\r\nA PyTorch perspective\u00b6\r\npin_memory()\u00b6\r\nPyTorch offers the possibility to create and send tensors to page-locked memory through the\r\npin_memory() method and constructor arguments.\r\nCPU tensors on a machine where CUDA is initialized can be cast to pinned memory through the pin_memory()\r\nmethod. Importantly, pin_memory is blocking on the main thread of the host: it will wait for the tensor to be copied to\r\npage-locked memory before executing the next operation.\r\nNew tensors can be directly created in pinned memory with functions like zeros(), ones() and other\r\nconstructors.", "mimetype": "text/plain", "start_char_idx": 51324, "end_char_idx": 55609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7bf5d248-bf26-4d2b-b4a4-867a5a070e89": {"__data__": {"id_": "7bf5d248-bf26-4d2b-b4a4-867a5a070e89", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66f4cf08-6189-4075-9bc4-12232900e7ba", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "b0a8c4588bdc50d2c7efb13d2234fc4d17d556d8ba8299c73c137650bac9c558", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a", "node_type": "1", "metadata": {}, "hash": "679bf4468ae76f63b279b9b12321b4bcd7d603687e14800755fd476807d874c5", "class_name": "RelatedNodeInfo"}}, "text": "CPU tensors on a machine where CUDA is initialized can be cast to pinned memory through the pin_memory()\r\nmethod. Importantly, pin_memory is blocking on the main thread of the host: it will wait for the tensor to be copied to\r\npage-locked memory before executing the next operation.\r\nNew tensors can be directly created in pinned memory with functions like zeros(), ones() and other\r\nconstructors.\r\nLet us check the speed of pinning memory and sending tensors to CUDA:\r\nimport torch\r\nimport gc\r\nfrom torch.utils.benchmark import Timer\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\ndef timer(cmd):\r\n    median = (\r\n        Timer(cmd, globals=globals())\r\n        .adaptive_autorange(min_run_time=1.0, max_run_time=20.0)\r\n        .median\r\n        * 1000\r\n    )\r\n    print(f\"{cmd}: {median: 4.4f} ms\")\r\n    return median\r\n\r\n\r\n# A tensor in pageable memory\r\npageable_tensor = torch.randn(1_000_000)\r\n\r\n# A tensor in page-locked (pinned) memory\r\npinned_tensor = torch.randn(1_000_000, pin_memory=True)\r\n\r\n# Runtimes:\r\npageable_to_device = timer(\"pageable_tensor.to('cuda:0')\")\r\npinned_to_device = timer(\"pinned_tensor.to('cuda:0')\")\r\npin_mem = timer(\"pageable_tensor.pin_memory()\")\r\npin_mem_to_device = timer(\"pageable_tensor.pin_memory().to('cuda:0')\")\r\n\r\n# Ratios:\r\nr1 = pinned_to_device / pageable_to_device\r\nr2 = pin_mem_to_device / pageable_to_device\r\n\r\n# Create a figure with the results\r\nfig, ax = plt.subplots()\r\n\r\nxlabels = [0, 1, 2]\r\nbar_labels = [\r\n    \"pageable_tensor.to(device) (1x)\",\r\n    f\"pinned_tensor.to(device) ({r1:4.2f}x)\",\r\n    f\"pageable_tensor.pin_memory().to(device) ({r2:4.2f}x)\"\r\n    f\"\\npin_memory()={100*pin_mem/pin_mem_to_device:.2f}% of runtime.\",\r\n]\r\nvalues = [pageable_to_device, pinned_to_device, pin_mem_to_device]\r\ncolors = [\"tab:blue\", \"tab:red\", \"tab:orange\"]\r\nax.bar(xlabels, values, label=bar_labels, color=colors)\r\n\r\nax.set_ylabel(\"Runtime (ms)\")\r\nax.set_title(\"Device casting runtime (pin-memory)\")\r\nax.set_xticks([])\r\nax.legend()\r\n\r\nplt.show()\r\n\r\n# Clear tensors\r\ndel pageable_tensor, pinned_tensor\r\n_ = gc.collect()\r\n\r\npageable_tensor.to('cuda:0'):  0.7791 ms\r\npinned_tensor.to('cuda:0'):  0.6806 ms\r\npageable_tensor.pin_memory():  0.3651 ms\r\npageable_tensor.pin_memory().to('cuda:0'):  1.0569 ms\r\n\r\nWe can observe that casting a pinned-memory tensor to GPU is indeed much faster than a pageable tensor, because under\r\nthe hood, a pageable tensor must be copied to pinned memory before being sent to GPU.\r\nHowever, contrary to a somewhat common belief, calling pin_memory() on a pageable tensor before\r\ncasting it to GPU should not bring any significant speed-up, on the contrary this call is usually slower than just\r\nexecuting the transfer. This makes sense, since we\u2019re actually asking Python to execute an operation that CUDA will\r\nperform anyway before copying the data from host to device.\r\nNote\r\nThe PyTorch implementation of\r\npin_memory\r\nwhich relies on creating a brand new storage in pinned memory through cudaHostAlloc\r\ncould be, in rare cases, faster than transitioning data in chunks as cudaMemcpy does.\r\nHere too, the observation may vary depending on the available hardware, the size of the tensors being sent or\r\nthe amount of available RAM.\r\nnon_blocking=True\u00b6\r\nAs mentioned earlier, many PyTorch operations have the option of being executed asynchronously with respect to the host\r\nthrough the non_blocking argument.\r\nHere, to account accurately of the benefits of using non_blocking, we will design a slightly more complex\r\nexperiment since we want to assess how fast it is to send multiple tensors to GPU with and without calling\r\nnon_blocking.\r\n# A simple loop that copies all tensors to cuda\r\ndef copy_to_device(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.to(\"cuda:0\"))\r\n    return result\r\n\r\n\r\n# A loop that copies all tensors to cuda asynchronously\r\ndef copy_to_device_nonblocking(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.to(\"cuda:0\", non_blocking=True))\r\n    # We need to synchronize\r\n    torch.cuda.synchronize()\r\n    return result\r\n\r\n\r\n# Create a list of tensors\r\ntensors = [torch.", "mimetype": "text/plain", "start_char_idx": 55212, "end_char_idx": 59337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a": {"__data__": {"id_": "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7bf5d248-bf26-4d2b-b4a4-867a5a070e89", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "1fee176a5f1498e79d9385349aa235f08a9be8500588443c1c3c7e38d9196644", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9", "node_type": "1", "metadata": {}, "hash": "eecaf65cb87da7228e13e840c7f4ee82268899f785712cec011899e15ae7ddba", "class_name": "RelatedNodeInfo"}}, "text": "Here, to account accurately of the benefits of using non_blocking, we will design a slightly more complex\r\nexperiment since we want to assess how fast it is to send multiple tensors to GPU with and without calling\r\nnon_blocking.\r\n# A simple loop that copies all tensors to cuda\r\ndef copy_to_device(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.to(\"cuda:0\"))\r\n    return result\r\n\r\n\r\n# A loop that copies all tensors to cuda asynchronously\r\ndef copy_to_device_nonblocking(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.to(\"cuda:0\", non_blocking=True))\r\n    # We need to synchronize\r\n    torch.cuda.synchronize()\r\n    return result\r\n\r\n\r\n# Create a list of tensors\r\ntensors = [torch.randn(1000) for _ in range(1000)]\r\nto_device = timer(\"copy_to_device(*tensors)\")\r\nto_device_nonblocking = timer(\"copy_to_device_nonblocking(*tensors)\")\r\n\r\n# Ratio\r\nr1 = to_device_nonblocking / to_device\r\n\r\n# Plot the results\r\nfig, ax = plt.subplots()\r\n\r\nxlabels = [0, 1]\r\nbar_labels = [f\"to(device) (1x)\", f\"to(device, non_blocking=True) ({r1:4.2f}x)\"]\r\ncolors = [\"tab:blue\", \"tab:red\"]\r\nvalues = [to_device, to_device_nonblocking]\r\n\r\nax.bar(xlabels, values, label=bar_labels, color=colors)\r\n\r\nax.set_ylabel(\"Runtime (ms)\")\r\nax.set_title(\"Device casting runtime (non-blocking)\")\r\nax.set_xticks([])\r\nax.legend()\r\n\r\nplt.show()\r\n\r\ncopy_to_device(*tensors):  24.9430 ms\r\ncopy_to_device_nonblocking(*tensors):  18.6000 ms\r\n\r\nTo get a better sense of what is happening here, let us profile these two functions:\r\nfrom torch.profiler import profile, ProfilerActivity\r\n\r\n\r\ndef profile_mem(cmd):\r\n    with profile(activities=[ProfilerActivity.CPU]) as prof:\r\n        exec(cmd)\r\n    print(cmd)\r\n    print(prof.key_averages().table(row_limit=10))\r\n\r\nLet\u2019s see the call stack with a regular to(device) first:\r\nprint(\"Call to `to(device)`\", profile_mem(\"copy_to_device(*tensors)\"))\r\n\r\ncopy_to_device(*tensors)\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                 aten::to         4.03%       1.196ms       100.00%      29.678ms      29.678us          1000\r\n           aten::_to_copy        13.13%       3.897ms        95.97%      28.482ms      28.482us          1000\r\n      aten::empty_strided        24.76%       7.348ms        24.76%       7.348ms       7.348us          1000\r\n              aten::copy_        19.31%       5.729ms        58.08%      17.237ms      17.237us          1000\r\n          cudaMemcpyAsync        18.28%       5.426ms        18.28%       5.426ms       5.426us          1000\r\n    cudaStreamSynchronize        20.49%       6.081ms        20.49%       6.081ms       6.081us          1000\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\nSelf CPU time total: 29.678ms\r\n\r\nCall to `to(device)` None\r\n\r\nand now the non_blocking version:\r\nprint(\r\n    \"Call to `to(device, non_blocking=True)`\",\r\n    profile_mem(\"copy_to_device_nonblocking(*tensors)\"),\r\n)\r\n\r\ncopy_to_device_nonblocking(*tensors)\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                 aten::to         4.70%       1.065ms        99.90%      22.634ms      22.634us          1000\r\n           aten::_to_copy        16.26%       3.683ms        95.20%      21.", "mimetype": "text/plain", "start_char_idx": 58579, "end_char_idx": 62418, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9": {"__data__": {"id_": "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "3649dff62c72d8f41904fcd9e337e60588de55475e50c301bbe0de3f5328f230", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5977c7fd-8154-47ac-88c1-a7ec95eac8a3", "node_type": "1", "metadata": {}, "hash": "77f4ee5eca6cb7d1744406f810e0f0e2af13173d25b63aaf550d9aacde412b88", "class_name": "RelatedNodeInfo"}}, "text": "678ms\r\n\r\nCall to `to(device)` None\r\n\r\nand now the non_blocking version:\r\nprint(\r\n    \"Call to `to(device, non_blocking=True)`\",\r\n    profile_mem(\"copy_to_device_nonblocking(*tensors)\"),\r\n)\r\n\r\ncopy_to_device_nonblocking(*tensors)\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\n                 aten::to         4.70%       1.065ms        99.90%      22.634ms      22.634us          1000\r\n           aten::_to_copy        16.26%       3.683ms        95.20%      21.569ms      21.569us          1000\r\n      aten::empty_strided        31.54%       7.145ms        31.54%       7.145ms       7.145us          1000\r\n              aten::copy_        22.93%       5.195ms        47.41%      10.741ms      10.741us          1000\r\n          cudaMemcpyAsync        24.48%       5.546ms        24.48%       5.546ms       5.546us          1000\r\n    cudaDeviceSynchronize         0.10%      22.474us         0.10%      22.474us      22.474us             1\r\n-------------------------  ------------  ------------  ------------  ------------  ------------  ------------\r\nSelf CPU time total: 22.657ms\r\n\r\nCall to `to(device, non_blocking=True)` None\r\n\r\nThe results are without any doubt better when using non_blocking=True, as all transfers are initiated simultaneously\r\non the host side and only one synchronization is done.\r\nThe benefit will vary depending on the number and the size of the tensors as well as depending on the hardware being\r\nused.\r\nNote\r\nInterestingly, the blocking to(\"cuda\") actually performs the same asynchronous device casting operation\r\n(cudaMemcpyAsync) as the one with non_blocking=True with a synchronization point after each copy.\r\nSynergies\u00b6\r\nNow that we have made the point that data transfer of tensors already in pinned memory to GPU is faster than from\r\npageable memory, and that we know that doing these transfers asynchronously is also faster than synchronously, we can\r\nbenchmark combinations of these approaches. First, let\u2019s write a couple of new functions that will call pin_memory\r\nand to(device) on each tensor:\r\ndef pin_copy_to_device(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.pin_memory().to(\"cuda:0\"))\r\n    return result\r\n\r\n\r\ndef pin_copy_to_device_nonblocking(*tensors):\r\n    result = []\r\n    for tensor in tensors:\r\n        result.append(tensor.pin_memory().to(\"cuda:0\", non_blocking=True))\r\n    # We need to synchronize\r\n    torch.cuda.synchronize()\r\n    return result\r\n\r\nThe benefits of using pin_memory() are more pronounced for\r\nsomewhat large batches of large tensors:\r\ntensors = [torch.randn(1_000_000) for _ in range(1000)]\r\npage_copy = timer(\"copy_to_device(*tensors)\")\r\npage_copy_nb = timer(\"copy_to_device_nonblocking(*tensors)\")\r\n\r\ntensors_pinned = [torch.randn(1_000_000, pin_memory=True) for _ in range(1000)]\r\npinned_copy = timer(\"copy_to_device(*tensors_pinned)\")\r\npinned_copy_nb = timer(\"copy_to_device_nonblocking(*tensors_pinned)\")\r\n\r\npin_and_copy = timer(\"pin_copy_to_device(*tensors)\")\r\npin_and_copy_nb = timer(\"pin_copy_to_device_nonblocking(*tensors)\")\r\n\r\n# Plot\r\nstrategies = (\"pageable copy\", \"pinned copy\", \"pin and copy\")\r\nblocking = {\r\n    \"blocking\": [page_copy, pinned_copy, pin_and_copy],\r\n    \"non-blocking\": [page_copy_nb, pinned_copy_nb, pin_and_copy_nb],\r\n}\r\n\r\nx = torch.arange(3)\r\nwidth = 0.25\r\nmultiplier = 0\r\n\r\n\r\nfig, ax = plt.subplots(layout=\"constrained\")\r\n\r\nfor attribute, runtimes in blocking.items():\r\n    offset = width * multiplier\r\n    rects = ax.bar(x + offset, runtimes, width, label=attribute)\r\n    ax.bar_label(rects, padding=3, fmt=\"%.2f\")\r\n    multiplier += 1\r\n\r\n# Add some text for labels, title and custom x-axis tick labels, etc.", "mimetype": "text/plain", "start_char_idx": 61668, "end_char_idx": 65611, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5977c7fd-8154-47ac-88c1-a7ec95eac8a3": {"__data__": {"id_": "5977c7fd-8154-47ac-88c1-a7ec95eac8a3", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "47075a566e78fe51a5721dafb27e515bf945a5d3ab862ce4ed3de0b1c0d764dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09d5e4de-49e7-476e-8e10-753bec7a5217", "node_type": "1", "metadata": {}, "hash": "052b34474e6af2a99c82311c2143e6e87b514b954db2d24e6f888dde6b8f4e00", "class_name": "RelatedNodeInfo"}}, "text": "ax.set_ylabel(\"Runtime (ms)\")\r\nax.set_title(\"Runtime (pin-mem and non-blocking)\")\r\nax.set_xticks([0, 1, 2])\r\nax.set_xticklabels(strategies)\r\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\r\nax.legend(loc=\"upper left\", ncols=3)\r\n\r\nplt.show()\r\n\r\ndel tensors, tensors_pinned\r\n_ = gc.collect()\r\n\r\ncopy_to_device(*tensors):  820.7590 ms\r\ncopy_to_device_nonblocking(*tensors):  659.2608 ms\r\ncopy_to_device(*tensors_pinned):  678.4663 ms\r\ncopy_to_device_nonblocking(*tensors_pinned):  654.3293 ms\r\npin_copy_to_device(*tensors):  1269.7422 ms\r\npin_copy_to_device_nonblocking(*tensors):  655.5188 ms\r\n\r\nOther copy directions (GPU -> CPU, CPU -> MPS)\u00b6\r\nUntil now, we have operated under the assumption that asynchronous copies from the CPU to the GPU are safe.\r\nThis is generally true because CUDA automatically handles synchronization to ensure that the data being accessed is\r\nvalid at read time.\r\nHowever, this guarantee does not extend to transfers in the opposite direction, from GPU to CPU.\r\nWithout explicit synchronization, these transfers offer no assurance that the copy will be complete at the time of\r\ndata access. Consequently, the data on the host might be incomplete or incorrect, effectively rendering it garbage:\r\ntensor = (\r\n    torch.arange(1, 1_000_000, dtype=torch.double, device=\"cuda\")\r\n    .expand(100, 999999)\r\n    .clone()\r\n)\r\ntorch.testing.assert_close(\r\n    tensor.mean(), torch.tensor(500_000, dtype=torch.double, device=\"cuda\")\r\n), tensor.mean()\r\ntry:\r\n    i = -1\r\n    for i in range(100):\r\n        cpu_tensor = tensor.to(\"cpu\", non_blocking=True)\r\n        torch.testing.assert_close(\r\n            cpu_tensor.mean(), torch.tensor(500_000, dtype=torch.double)\r\n        )\r\n    print(\"No test failed with non_blocking\")\r\nexcept AssertionError:\r\n    print(f\"{i}th test failed with non_blocking. Skipping remaining tests\")\r\ntry:\r\n    i = -1\r\n    for i in range(100):\r\n        cpu_tensor = tensor.to(\"cpu\", non_blocking=True)\r\n        torch.cuda.synchronize()\r\n        torch.testing.assert_close(\r\n            cpu_tensor.mean(), torch.tensor(500_000, dtype=torch.double)\r\n        )\r\n    print(\"No test failed with synchronize\")\r\nexcept AssertionError:\r\n    print(f\"One test failed with synchronize: {i}th assertion!\")\r\n\r\n0th test failed with non_blocking. Skipping remaining tests\r\nNo test failed with synchronize\r\n\r\nThe same considerations apply to copies from the CPU to non-CUDA devices, such as MPS.\r\nGenerally, asynchronous copies to a device are safe without explicit synchronization only when the target is a\r\nCUDA-enabled device.\r\nIn summary, copying data from CPU to GPU is safe when using non_blocking=True, but for any other direction,\r\nnon_blocking=True can still be used but the user must make sure that a device synchronization is executed before\r\nthe data is accessed.\r\nPractical recommendations\u00b6\r\nWe can now wrap up some early recommendations based on our observations:\r\nIn general, non_blocking=True will provide good throughput, regardless of whether the original tensor is or\r\nisn\u2019t in pinned memory.\r\nIf the tensor is already in pinned memory, the transfer can be accelerated, but sending it to\r\npin memory manually from python main thread is a blocking operation on the host, and hence will annihilate much of\r\nthe benefit of using non_blocking=True (as CUDA does the pin_memory transfer anyway).\r\nOne might now legitimately ask what use there is for the pin_memory() method.\r\nIn the following section, we will explore further how this can be used to accelerate the data transfer even more.\r\nAdditional considerations\u00b6\r\nPyTorch notoriously provides a DataLoader class whose constructor accepts a\r\npin_memory argument.\r\nConsidering our previous discussion on pin_memory, you might wonder how the DataLoader manages to\r\naccelerate data transfers if memory pinning is inherently blocking.\r\nThe key lies in the DataLoader\u2019s use of a separate thread to handle the transfer of data from pageable to pinned\r\nmemory, thus preventing any blockage in the main thread.\r\nTo illustrate this, we will use the TensorDict primitive from the homonymous library.\r\nWhen invoking to(), the default behavior is to send tensors to the device asynchronously,\r\nfollowed by a single call to torch.device.synchronize() afterwards.\r\nAdditionally, TensorDict.to() includes a non_blocking_pin option  which initiates multiple threads to execute\r\npin_memory() before proceeding with to to(device).\r\nThis approach can further accelerate data transfers, as demonstrated in the following example.", "mimetype": "text/plain", "start_char_idx": 65613, "end_char_idx": 70143, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09d5e4de-49e7-476e-8e10-753bec7a5217": {"__data__": {"id_": "09d5e4de-49e7-476e-8e10-753bec7a5217", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5977c7fd-8154-47ac-88c1-a7ec95eac8a3", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "0e462f518f95ade986b125aed7ffb8dae9bb6fe9cafc2deaaa28a1642678a805", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec258b35-78d6-4569-ac78-ee008449df60", "node_type": "1", "metadata": {}, "hash": "6033c047f809365272a4c6c2983eefa4f611e0d6ad479236f435f78c12f45153", "class_name": "RelatedNodeInfo"}}, "text": "In the following section, we will explore further how this can be used to accelerate the data transfer even more.\r\nAdditional considerations\u00b6\r\nPyTorch notoriously provides a DataLoader class whose constructor accepts a\r\npin_memory argument.\r\nConsidering our previous discussion on pin_memory, you might wonder how the DataLoader manages to\r\naccelerate data transfers if memory pinning is inherently blocking.\r\nThe key lies in the DataLoader\u2019s use of a separate thread to handle the transfer of data from pageable to pinned\r\nmemory, thus preventing any blockage in the main thread.\r\nTo illustrate this, we will use the TensorDict primitive from the homonymous library.\r\nWhen invoking to(), the default behavior is to send tensors to the device asynchronously,\r\nfollowed by a single call to torch.device.synchronize() afterwards.\r\nAdditionally, TensorDict.to() includes a non_blocking_pin option  which initiates multiple threads to execute\r\npin_memory() before proceeding with to to(device).\r\nThis approach can further accelerate data transfers, as demonstrated in the following example.\r\nfrom tensordict import TensorDict\r\nimport torch\r\nfrom torch.utils.benchmark import Timer\r\nimport matplotlib.pyplot as plt\r\n\r\n# Create the dataset\r\ntd = TensorDict({str(i): torch.randn(1_000_000) for i in range(1000)})\r\n\r\n# Runtimes\r\ncopy_blocking = timer(\"td.to('cuda:0', non_blocking=False)\")\r\ncopy_non_blocking = timer(\"td.to('cuda:0')\")\r\ncopy_pin_nb = timer(\"td.to('cuda:0', non_blocking_pin=True, num_threads=0)\")\r\ncopy_pin_multithread_nb = timer(\"td.to('cuda:0', non_blocking_pin=True, num_threads=4)\")\r\n\r\n# Rations\r\nr1 = copy_non_blocking / copy_blocking\r\nr2 = copy_pin_nb / copy_blocking\r\nr3 = copy_pin_multithread_nb / copy_blocking\r\n\r\n# Figure\r\nfig, ax = plt.subplots()\r\n\r\nxlabels = [0, 1, 2, 3]\r\nbar_labels = [\r\n    \"Blocking copy (1x)\",\r\n    f\"Non-blocking copy ({r1:4.2f}x)\",\r\n    f\"Blocking pin, non-blocking copy ({r2:4.2f}x)\",\r\n    f\"Non-blocking pin, non-blocking copy ({r3:4.2f}x)\",\r\n]\r\nvalues = [copy_blocking, copy_non_blocking, copy_pin_nb, copy_pin_multithread_nb]\r\ncolors = [\"tab:blue\", \"tab:red\", \"tab:orange\", \"tab:green\"]\r\n\r\nax.bar(xlabels, values, label=bar_labels, color=colors)\r\n\r\nax.set_ylabel(\"Runtime (ms)\")\r\nax.set_title(\"Device casting runtime\")\r\nax.set_xticks([])\r\nax.legend()\r\n\r\nplt.show()\r\n\r\ntd.to('cuda:0', non_blocking=False):  820.9782 ms\r\ntd.to('cuda:0'):  659.1453 ms\r\ntd.to('cuda:0', non_blocking_pin=True, num_threads=0):  655.0730 ms\r\ntd.to('cuda:0', non_blocking_pin=True, num_threads=4):  657.1083 ms\r\n\r\nIn this example, we are transferring many large tensors from the CPU to the GPU.\r\nThis scenario is ideal for utilizing multithreaded pin_memory(), which can significantly enhance performance.\r\nHowever, if the tensors are small, the overhead associated with multithreading may outweigh the benefits.\r\nSimilarly, if there are only a few tensors, the advantages of pinning tensors on separate threads become limited.\r\nAs an additional note, while it might seem advantageous to create permanent buffers in pinned memory to shuttle\r\ntensors from pageable memory before transferring them to the GPU, this strategy does not necessarily expedite\r\ncomputation. The inherent bottleneck caused by copying data into pinned memory remains a limiting factor.\r\nMoreover, transferring data that resides on disk (whether in shared memory or files) to the GPU typically requires an\r\nintermediate step of copying the data into pinned memory (located in RAM).\r\nUtilizing non_blocking for large data transfers in this context can significantly increase RAM consumption,\r\npotentially leading to adverse effects.\r\nIn practice, there is no one-size-fits-all solution.\r\nThe effectiveness of using multithreaded pin_memory combined with non_blocking transfers depends on a\r\nvariety of  factors, including the specific system, operating system, hardware, and the nature of the tasks\r\nbeing executed.\r\nHere is a list of factors to check when trying to speed-up data transfers between CPU and GPU, or comparing\r\nthroughput\u2019s across scenarios:\r\nNumber of available cores\r\nHow many CPU cores are available? Is the system shared with other users or processes that might compete for\r\nresources?\r\nCore utilization\r\nAre the CPU cores heavily utilized by other processes? Does the application perform other CPU-intensive tasks\r\nconcurrently with data transfers?\r\nMemory utilization\r\nHow much pageable and page-locked memory is currently being used?", "mimetype": "text/plain", "start_char_idx": 69057, "end_char_idx": 73507, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec258b35-78d6-4569-ac78-ee008449df60": {"__data__": {"id_": "ec258b35-78d6-4569-ac78-ee008449df60", "embedding": null, "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1dafc231-ac33-42a2-9ba6-51f57e50c745", "node_type": "4", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "2face2c7165434a7047c6982b1da88361286c4219b3910dc8df3a4d9bbe03831", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09d5e4de-49e7-476e-8e10-753bec7a5217", "node_type": "1", "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}, "hash": "356cac4388c805f26cf74a6af27b37d05a53b685f05be03d96ad8a181ea81830", "class_name": "RelatedNodeInfo"}}, "text": "Utilizing non_blocking for large data transfers in this context can significantly increase RAM consumption,\r\npotentially leading to adverse effects.\r\nIn practice, there is no one-size-fits-all solution.\r\nThe effectiveness of using multithreaded pin_memory combined with non_blocking transfers depends on a\r\nvariety of  factors, including the specific system, operating system, hardware, and the nature of the tasks\r\nbeing executed.\r\nHere is a list of factors to check when trying to speed-up data transfers between CPU and GPU, or comparing\r\nthroughput\u2019s across scenarios:\r\nNumber of available cores\r\nHow many CPU cores are available? Is the system shared with other users or processes that might compete for\r\nresources?\r\nCore utilization\r\nAre the CPU cores heavily utilized by other processes? Does the application perform other CPU-intensive tasks\r\nconcurrently with data transfers?\r\nMemory utilization\r\nHow much pageable and page-locked memory is currently being used? Is there sufficient free memory to allocate\r\nadditional pinned memory without affecting system performance? Remember that nothing comes for free, for instance\r\npin_memory will consume RAM and may impact other tasks.\r\nCUDA Device Capabilities\r\nDoes the GPU support multiple DMA engines for concurrent data transfers? What are the specific capabilities and\r\nlimitations of the CUDA device being used?\r\nNumber of tensors to be sent\r\nHow many tensors are transferred in a typical operation?\r\nSize of the tensors to be sent\r\nWhat is the size of the tensors being transferred? A few large tensors or many small tensors may not benefit from\r\nthe same transfer program.\r\nSystem Architecture\r\nHow is the system\u2019s architecture influencing data transfer speeds (for example, bus speeds, network latency)?\r\nAdditionally, allocating a large number of tensors or sizable tensors in pinned memory can monopolize a substantial\r\nportion of RAM.\r\nThis reduces the available memory for other critical operations, such as paging, which can negatively impact the\r\noverall performance of an algorithm.\r\nConclusion\u00b6\r\nThroughout this tutorial, we have explored several critical factors that influence transfer speeds and memory\r\nmanagement when sending tensors from the host to the device. We\u2019ve learned that using non_blocking=True generally\r\naccelerates data transfers, and that pin_memory() can also enhance performance if implemented\r\ncorrectly. However, these techniques require careful design and calibration to be effective.\r\nRemember that profiling your code and keeping an eye on the memory consumption are essential to optimize resource\r\nusage and achieve the best possible performance.\r\nAdditional resources\u00b6\r\nIf you are dealing with issues with memory copies when using CUDA devices or want to learn more about\r\nwhat was discussed in this tutorial, check the following references:\r\nCUDA toolkit memory management doc;\r\nCUDA pin-memory note;\r\nHow to Optimize Data Transfers in CUDA C/C++;\r\ntensordict doc and repo.\r\nTotal running time of the script: ( 1 minutes  31.484 seconds)\r\nDownload Python source code: pinmem_nonblock.py\r\nDownload Jupyter notebook: pinmem_nonblock.ipynb\r\nGallery generated by Sphinx-Gallery", "mimetype": "text/plain", "start_char_idx": 72536, "end_char_idx": 75709, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"1dafc231-ac33-42a2-9ba6-51f57e50c745": {"node_ids": ["ffa913d6-c325-43cc-9dcb-88ff057cd299", "e817ba43-2e88-4f2a-9312-c8e8b2bec861", "ab0cc3e2-d363-4e8c-aea2-9cc8400c62d3", "0b095bdf-d36b-4cb1-9daf-b825fccc4454", "3f5f9832-7688-4224-a518-9f4fc121f9f0", "2302ec12-42e0-401f-a583-e8eda45ffa5c", "01be9aa7-d9d4-47ba-9342-8bd7c24fb61a", "2c4ef1d9-e443-4aa2-ae6f-86accede988f", "4af45910-e0cc-4b75-9e08-244fe6521e48", "18fcb37a-0626-46dc-ba3a-14926ba7fecc", "8407cd9a-84c0-47bb-8e34-3605577eb0cb", "fd851d4a-b424-4e30-a021-f3305816aa79", "195e5394-e1ed-4853-bfc1-ed656d7cf660", "ab2e2a4a-d7bb-4da7-8889-1b1522ad73d6", "b5538188-352c-42a8-9b6e-8ab697391766", "66f4cf08-6189-4075-9bc4-12232900e7ba", "7bf5d248-bf26-4d2b-b4a4-867a5a070e89", "2592dbb4-7183-4bc0-9b55-5f7b6b1a833a", "7b63fdd2-ae06-412e-a9ff-17aad4da8ed9", "5977c7fd-8154-47ac-88c1-a7ec95eac8a3", "09d5e4de-49e7-476e-8e10-753bec7a5217", "ec258b35-78d6-4569-ac78-ee008449df60"], "metadata": {"file_path": "data\\raw\\conceptual_content.txt", "file_name": "conceptual_content.txt", "file_type": "text/plain", "file_size": 76035, "creation_date": "2024-10-30", "last_modified_date": "2024-10-30"}}}}